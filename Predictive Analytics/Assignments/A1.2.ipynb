{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sl\n",
    "import matplotlib as mp\n",
    "import scipy as cp\n",
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
    "from sklearn.metrics import f1_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from math import sqrt\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tDownload the “dataset_lm.csv” file from Canvas and upload it to Jupyter Notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\johns\\OneDrive\\Desktop\\MBAN Semester 2\\Predictive Analytics\\Assignment 1\\dataset_lm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependent Var</th>\n",
       "      <th>Explanatory Var #1</th>\n",
       "      <th>Explanatory Var #2</th>\n",
       "      <th>Explanatory Var #3</th>\n",
       "      <th>Explanatory Var #4</th>\n",
       "      <th>Explanatory Var #5</th>\n",
       "      <th>Explanatory Var #6</th>\n",
       "      <th>Explanatory Var #7</th>\n",
       "      <th>Explanatory Var #8</th>\n",
       "      <th>Explanatory Var #9</th>\n",
       "      <th>Explanatory Var #10</th>\n",
       "      <th>Explanatory Var #11</th>\n",
       "      <th>Explanatory Var #12</th>\n",
       "      <th>Explanatory Var #13</th>\n",
       "      <th>Explanatory Var #14</th>\n",
       "      <th>Explanatory Var #15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.293458</td>\n",
       "      <td>13.698667</td>\n",
       "      <td>50.639873</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.568035</td>\n",
       "      <td>45.121911</td>\n",
       "      <td>11.412501</td>\n",
       "      <td>56.410757</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.281132</td>\n",
       "      <td>38.996909</td>\n",
       "      <td>-3.010548</td>\n",
       "      <td>49.195073</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.153143</td>\n",
       "      <td>46.919314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.473431</td>\n",
       "      <td>2.714725</td>\n",
       "      <td>65.845845</td>\n",
       "      <td>1</td>\n",
       "      <td>-25.105932</td>\n",
       "      <td>47.190213</td>\n",
       "      <td>10.080280</td>\n",
       "      <td>65.383107</td>\n",
       "      <td>3</td>\n",
       "      <td>-36.763585</td>\n",
       "      <td>51.654939</td>\n",
       "      <td>4.991111</td>\n",
       "      <td>45.591729</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.474403</td>\n",
       "      <td>53.383508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.195330</td>\n",
       "      <td>11.618072</td>\n",
       "      <td>65.072497</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.897464</td>\n",
       "      <td>52.163036</td>\n",
       "      <td>11.057301</td>\n",
       "      <td>82.812717</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.733547</td>\n",
       "      <td>48.913837</td>\n",
       "      <td>-2.457696</td>\n",
       "      <td>56.608806</td>\n",
       "      <td>0</td>\n",
       "      <td>-27.903299</td>\n",
       "      <td>48.515026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.074583</td>\n",
       "      <td>0.818623</td>\n",
       "      <td>45.408996</td>\n",
       "      <td>1</td>\n",
       "      <td>-18.316132</td>\n",
       "      <td>54.356714</td>\n",
       "      <td>5.029029</td>\n",
       "      <td>48.812471</td>\n",
       "      <td>1</td>\n",
       "      <td>-12.825591</td>\n",
       "      <td>45.851732</td>\n",
       "      <td>14.974177</td>\n",
       "      <td>47.362594</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.064411</td>\n",
       "      <td>55.266254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86.035569</td>\n",
       "      <td>9.077544</td>\n",
       "      <td>73.548021</td>\n",
       "      <td>0</td>\n",
       "      <td>-19.204165</td>\n",
       "      <td>47.186807</td>\n",
       "      <td>12.128134</td>\n",
       "      <td>62.520911</td>\n",
       "      <td>2</td>\n",
       "      <td>-13.804860</td>\n",
       "      <td>47.765904</td>\n",
       "      <td>9.593982</td>\n",
       "      <td>53.700562</td>\n",
       "      <td>0</td>\n",
       "      <td>-17.546302</td>\n",
       "      <td>48.150543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dependent Var  Explanatory Var #1  Explanatory Var #2  Explanatory Var #3  \\\n",
       "0      56.293458           13.698667           50.639873                   0   \n",
       "1      58.473431            2.714725           65.845845                   1   \n",
       "2      94.195330           11.618072           65.072497                   0   \n",
       "3      29.074583            0.818623           45.408996                   1   \n",
       "4      86.035569            9.077544           73.548021                   0   \n",
       "\n",
       "   Explanatory Var #4  Explanatory Var #5  Explanatory Var #6  \\\n",
       "0          -18.568035           45.121911           11.412501   \n",
       "1          -25.105932           47.190213           10.080280   \n",
       "2           -7.897464           52.163036           11.057301   \n",
       "3          -18.316132           54.356714            5.029029   \n",
       "4          -19.204165           47.186807           12.128134   \n",
       "\n",
       "   Explanatory Var #7  Explanatory Var #8  Explanatory Var #9  \\\n",
       "0           56.410757                   2          -12.281132   \n",
       "1           65.383107                   3          -36.763585   \n",
       "2           82.812717                   0          -15.733547   \n",
       "3           48.812471                   1          -12.825591   \n",
       "4           62.520911                   2          -13.804860   \n",
       "\n",
       "   Explanatory Var #10  Explanatory Var #11  Explanatory Var #12  \\\n",
       "0            38.996909            -3.010548            49.195073   \n",
       "1            51.654939             4.991111            45.591729   \n",
       "2            48.913837            -2.457696            56.608806   \n",
       "3            45.851732            14.974177            47.362594   \n",
       "4            47.765904             9.593982            53.700562   \n",
       "\n",
       "   Explanatory Var #13  Explanatory Var #14  Explanatory Var #15  \n",
       "0                    0           -21.153143            46.919314  \n",
       "1                    0            -6.474403            53.383508  \n",
       "2                    0           -27.903299            48.515026  \n",
       "3                    1           -10.064411            55.266254  \n",
       "4                    0           -17.546302            48.150543  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422 entries, 0 to 421\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Dependent Var        422 non-null    float64\n",
      " 1   Explanatory Var #1   422 non-null    float64\n",
      " 2   Explanatory Var #2   422 non-null    float64\n",
      " 3   Explanatory Var #3   422 non-null    int64  \n",
      " 4   Explanatory Var #4   422 non-null    float64\n",
      " 5   Explanatory Var #5   422 non-null    float64\n",
      " 6   Explanatory Var #6   422 non-null    float64\n",
      " 7   Explanatory Var #7   422 non-null    float64\n",
      " 8   Explanatory Var #8   422 non-null    int64  \n",
      " 9   Explanatory Var #9   422 non-null    float64\n",
      " 10  Explanatory Var #10  422 non-null    float64\n",
      " 11  Explanatory Var #11  422 non-null    float64\n",
      " 12  Explanatory Var #12  422 non-null    float64\n",
      " 13  Explanatory Var #13  422 non-null    int64  \n",
      " 14  Explanatory Var #14  422 non-null    float64\n",
      " 15  Explanatory Var #15  422 non-null    float64\n",
      "dtypes: float64(13), int64(3)\n",
      "memory usage: 52.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tRun the OLS model by using the dependent and explanatory variables in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Dependent Var']\n",
    "X = df.drop('Dependent Var', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "??? do I add a constant - sm.add_constant(x)\n",
    "\n",
    "add one because of this\n",
    "\n",
    "Notes:\n",
    "\n",
    "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
    "\n",
    "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg = sm.OLS(y,X).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tShow your summary table in Python and interpret your results in the summary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Dependent Var</td>  <th>  R-squared (uncentered):</th>      <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>4.509e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 23 Oct 2023</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:20:27</td>     <th>  Log-Likelihood:    </th>          <td> -841.76</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   422</td>      <th>  AIC:               </th>          <td>   1714.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   407</td>      <th>  BIC:               </th>          <td>   1774.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #1</th>  <td>    1.3078</td> <td>    0.013</td> <td>  102.159</td> <td> 0.000</td> <td>    1.283</td> <td>    1.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #2</th>  <td>    1.7667</td> <td>    0.009</td> <td>  203.101</td> <td> 0.000</td> <td>    1.750</td> <td>    1.784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #3</th>  <td>    6.6083</td> <td>    0.177</td> <td>   37.232</td> <td> 0.000</td> <td>    6.259</td> <td>    6.957</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #4</th>  <td>    2.0725</td> <td>    0.011</td> <td>  189.896</td> <td> 0.000</td> <td>    2.051</td> <td>    2.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #5</th>  <td>   -0.7776</td> <td>    0.011</td> <td>  -68.372</td> <td> 0.000</td> <td>   -0.800</td> <td>   -0.755</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #6</th>  <td>    0.0124</td> <td>    0.008</td> <td>    1.595</td> <td> 0.111</td> <td>   -0.003</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #7</th>  <td>    0.0286</td> <td>    0.006</td> <td>    4.890</td> <td> 0.000</td> <td>    0.017</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #8</th>  <td>    0.3510</td> <td>    0.080</td> <td>    4.398</td> <td> 0.000</td> <td>    0.194</td> <td>    0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #9</th>  <td>   -0.0293</td> <td>    0.010</td> <td>   -2.838</td> <td> 0.005</td> <td>   -0.050</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #10</th> <td>    0.1292</td> <td>    0.011</td> <td>   11.409</td> <td> 0.000</td> <td>    0.107</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #11</th> <td>    0.0145</td> <td>    0.013</td> <td>    1.152</td> <td> 0.250</td> <td>   -0.010</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #12</th> <td>    0.0752</td> <td>    0.009</td> <td>    8.698</td> <td> 0.000</td> <td>    0.058</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #13</th> <td>    0.7414</td> <td>    0.177</td> <td>    4.198</td> <td> 0.000</td> <td>    0.394</td> <td>    1.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #14</th> <td>   -0.0218</td> <td>    0.011</td> <td>   -1.974</td> <td> 0.049</td> <td>   -0.043</td> <td>-8.61e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #15</th> <td>    0.1212</td> <td>    0.012</td> <td>   10.324</td> <td> 0.000</td> <td>    0.098</td> <td>    0.144</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.087</td> <th>  Durbin-Watson:     </th> <td>   1.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.957</td> <th>  Jarque-Bera (JB):  </th> <td>   0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.004</td> <th>  Prob(JB):          </th> <td>   0.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.897</td> <th>  Cond. No.          </th> <td>    287.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       &  Dependent Var   & \\textbf{  R-squared (uncentered):}      &     0.999   \\\\\n",
       "\\textbf{Model:}               &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.999   \\\\\n",
       "\\textbf{Method:}              &  Least Squares   & \\textbf{  F-statistic:       }          & 4.509e+04   \\\\\n",
       "\\textbf{Date:}                & Mon, 23 Oct 2023 & \\textbf{  Prob (F-statistic):}          &     0.00    \\\\\n",
       "\\textbf{Time:}                &     21:20:27     & \\textbf{  Log-Likelihood:    }          &   -841.76   \\\\\n",
       "\\textbf{No. Observations:}    &         422      & \\textbf{  AIC:               }          &     1714.   \\\\\n",
       "\\textbf{Df Residuals:}        &         407      & \\textbf{  BIC:               }          &     1774.   \\\\\n",
       "\\textbf{Df Model:}            &          15      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}     &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Explanatory Var \\#1}  &       1.3078  &        0.013     &   102.159  &         0.000        &        1.283    &        1.333     \\\\\n",
       "\\textbf{Explanatory Var \\#2}  &       1.7667  &        0.009     &   203.101  &         0.000        &        1.750    &        1.784     \\\\\n",
       "\\textbf{Explanatory Var \\#3}  &       6.6083  &        0.177     &    37.232  &         0.000        &        6.259    &        6.957     \\\\\n",
       "\\textbf{Explanatory Var \\#4}  &       2.0725  &        0.011     &   189.896  &         0.000        &        2.051    &        2.094     \\\\\n",
       "\\textbf{Explanatory Var \\#5}  &      -0.7776  &        0.011     &   -68.372  &         0.000        &       -0.800    &       -0.755     \\\\\n",
       "\\textbf{Explanatory Var \\#6}  &       0.0124  &        0.008     &     1.595  &         0.111        &       -0.003    &        0.028     \\\\\n",
       "\\textbf{Explanatory Var \\#7}  &       0.0286  &        0.006     &     4.890  &         0.000        &        0.017    &        0.040     \\\\\n",
       "\\textbf{Explanatory Var \\#8}  &       0.3510  &        0.080     &     4.398  &         0.000        &        0.194    &        0.508     \\\\\n",
       "\\textbf{Explanatory Var \\#9}  &      -0.0293  &        0.010     &    -2.838  &         0.005        &       -0.050    &       -0.009     \\\\\n",
       "\\textbf{Explanatory Var \\#10} &       0.1292  &        0.011     &    11.409  &         0.000        &        0.107    &        0.152     \\\\\n",
       "\\textbf{Explanatory Var \\#11} &       0.0145  &        0.013     &     1.152  &         0.250        &       -0.010    &        0.039     \\\\\n",
       "\\textbf{Explanatory Var \\#12} &       0.0752  &        0.009     &     8.698  &         0.000        &        0.058    &        0.092     \\\\\n",
       "\\textbf{Explanatory Var \\#13} &       0.7414  &        0.177     &     4.198  &         0.000        &        0.394    &        1.089     \\\\\n",
       "\\textbf{Explanatory Var \\#14} &      -0.0218  &        0.011     &    -1.974  &         0.049        &       -0.043    &    -8.61e-05     \\\\\n",
       "\\textbf{Explanatory Var \\#15} &       0.1212  &        0.012     &    10.324  &         0.000        &        0.098    &        0.144     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.087 & \\textbf{  Durbin-Watson:     } &    1.875  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.957 & \\textbf{  Jarque-Bera (JB):  } &    0.188  \\\\\n",
       "\\textbf{Skew:}          & -0.004 & \\textbf{  Prob(JB):          } &    0.910  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.897 & \\textbf{  Cond. No.          } &     287.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:          Dependent Var   R-squared (uncentered):                   0.999\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.999\n",
       "Method:                 Least Squares   F-statistic:                          4.509e+04\n",
       "Date:                Mon, 23 Oct 2023   Prob (F-statistic):                        0.00\n",
       "Time:                        21:20:27   Log-Likelihood:                         -841.76\n",
       "No. Observations:                 422   AIC:                                      1714.\n",
       "Df Residuals:                     407   BIC:                                      1774.\n",
       "Df Model:                          15                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "Explanatory Var #1      1.3078      0.013    102.159      0.000       1.283       1.333\n",
       "Explanatory Var #2      1.7667      0.009    203.101      0.000       1.750       1.784\n",
       "Explanatory Var #3      6.6083      0.177     37.232      0.000       6.259       6.957\n",
       "Explanatory Var #4      2.0725      0.011    189.896      0.000       2.051       2.094\n",
       "Explanatory Var #5     -0.7776      0.011    -68.372      0.000      -0.800      -0.755\n",
       "Explanatory Var #6      0.0124      0.008      1.595      0.111      -0.003       0.028\n",
       "Explanatory Var #7      0.0286      0.006      4.890      0.000       0.017       0.040\n",
       "Explanatory Var #8      0.3510      0.080      4.398      0.000       0.194       0.508\n",
       "Explanatory Var #9     -0.0293      0.010     -2.838      0.005      -0.050      -0.009\n",
       "Explanatory Var #10     0.1292      0.011     11.409      0.000       0.107       0.152\n",
       "Explanatory Var #11     0.0145      0.013      1.152      0.250      -0.010       0.039\n",
       "Explanatory Var #12     0.0752      0.009      8.698      0.000       0.058       0.092\n",
       "Explanatory Var #13     0.7414      0.177      4.198      0.000       0.394       1.089\n",
       "Explanatory Var #14    -0.0218      0.011     -1.974      0.049      -0.043   -8.61e-05\n",
       "Explanatory Var #15     0.1212      0.012     10.324      0.000       0.098       0.144\n",
       "==============================================================================\n",
       "Omnibus:                        0.087   Durbin-Watson:                   1.875\n",
       "Prob(Omnibus):                  0.957   Jarque-Bera (JB):                0.188\n",
       "Skew:                          -0.004   Prob(JB):                        0.910\n",
       "Kurtosis:                       2.897   Cond. No.                         287.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reg.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependent Variable: The dependent variable is referred to as \"Dependent Var,\" and the analysis aims to explain its variation based on the independent variables.\n",
    "\n",
    "R-squared: The R-squared value is a measure of how well the independent variables explain the variation in the dependent variable. In this case, the uncentered R-squared is very high at 0.999, indicating that the independent variables together explain 99.9% of the variation in the dependent variable.\n",
    "\n",
    "Adj. R-squared: The adjusted R-squared takes into account the number of independent variables in the model. In this case, the uncentered adjusted R-squared is also very high at 0.999.\n",
    "\n",
    "F-statistic: The F-statistic is used to test the overall significance of the regression model. A high F-statistic, in this case, 4.509e+04, suggests that the model as a whole is statistically significant.\n",
    "\n",
    "Prob (F-statistic): The probability associated with the F-statistic is very low (0.00), indicating that the overall model is highly statistically significant.\n",
    "\n",
    "No. Observations: There are 422 observations in the dataset.\n",
    "\n",
    "Degrees of Freedom (Df Residuals, Df Model):\n",
    "\n",
    "Df Residuals: 407 degrees of freedom for the residuals.\n",
    "\n",
    "Df Model: 15 degrees of freedom for the model.\n",
    "\n",
    "Covariance Type: The analysis was performed using a non-robust covariance type.\n",
    "\n",
    "Coefficients (coef): The coefficients for each of the 15 explanatory variables (independent variables) are provided, along with their standard errors.\n",
    "\n",
    "t-statistic (t): The t-statistic measures the significance of each coefficient. A higher absolute t-value indicates greater significance.\n",
    "\n",
    "P>|t| (p-value): This represents the probability that the coefficient is not significantly different from zero. Low p-values (typically < 0.05) suggest that the corresponding variable is statistically significant in explaining the dependent variable.\n",
    "[0.025 0.975]: These values provide a 95% confidence interval for each coefficient.\n",
    "\n",
    "Omnibus: The Omnibus test is a test of the normality of the residuals. A higher value is generally better, and a p-value close to 1 indicates that the residuals are normally distributed.\n",
    "\n",
    "Durbin-Watson: This statistic tests for the presence of autocorrelation (correlation of residuals at different points in time). A value close to 2 (in this case, 1.875) is often considered desirable as it suggests little autocorrelation.\n",
    "\n",
    "Jarque-Bera (JB): The Jarque-Bera test also assesses the normality of residuals.\n",
    "\n",
    "Skew: Measures the skewness of the residuals. A value close to 0 suggests a symmetric distribution.\n",
    "\n",
    "Kurtosis: Measures the kurtosis of the residuals. A value of 2.897 indicates the shape of the distribution of residuals.\n",
    "\n",
    "Cond. No.: The condition number (287) is a measure of multicollinearity, with higher values indicating a potential issue with multicollinearity among the independent variables.\n",
    "\n",
    "In summary, this regression analysis appears to have a very high R-squared value, indicating that the independent variables explain a significant portion of the variation in the dependent variable. The F-statistic and associated p-value suggest that the model is highly significant. The individual coefficients and their p-values allow you to assess the significance of each independent variable in explaining the dependent variable. Additionally, the diagnostic tests (Omnibus, Durbin-Watson, Jarque-Bera, Skew, and Kurtosis) provide insights into the quality of the model and the distribution of residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tUse error values from the OLS model to calculate their standard deviation and autocorrelation values for the first three lags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      4.825713\n",
       "1     -0.197803\n",
       "2      0.975013\n",
       "3      1.853953\n",
       "4      1.110946\n",
       "         ...   \n",
       "417   -3.236116\n",
       "418   -0.454778\n",
       "419    2.851672\n",
       "420   -2.647010\n",
       "421    1.035218\n",
       "Length: 422, dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_vals = model_reg.predict(X)\n",
    "errors = y - pred_vals\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7757282184664"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_dev = np.std(errors)\n",
    "st_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9338889427200325, 0.8568714054990086, 0.8841512562268686]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lags = 3\n",
    "autocorrelation = [np.corrcoef(df[i:], df[:-i])[0, 1] for i in range(1, lags + 1)]\n",
    "autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tThen, run the GLS model accordingly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get from lesson 3\n",
    "\n",
    "use cov_matrix function (1, cov1, cov2, cov3, np.zeros(418))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "gls_model = sm.GLS(y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\genmod\\cov_struct.py:796: FutureWarning: grid=True will become default in a future version\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "order = 1\n",
    "cov_structure = sm.cov_struct.Autoregressive(order)\n",
    "gls_model.cov_struct = cov_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "gls_results = gls_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tShow your summary table in Python and interpret your results in the summary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 GLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:          Dependent Var   R-squared (uncentered):                   0.999\n",
      "Model:                            GLS   Adj. R-squared (uncentered):              0.999\n",
      "Method:                 Least Squares   F-statistic:                          4.509e+04\n",
      "Date:                Mon, 23 Oct 2023   Prob (F-statistic):                        0.00\n",
      "Time:                        21:20:27   Log-Likelihood:                         -841.76\n",
      "No. Observations:                 422   AIC:                                      1714.\n",
      "Df Residuals:                     407   BIC:                                      1774.\n",
      "Df Model:                          15                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Explanatory Var #1      1.3078      0.013    102.159      0.000       1.283       1.333\n",
      "Explanatory Var #2      1.7667      0.009    203.101      0.000       1.750       1.784\n",
      "Explanatory Var #3      6.6083      0.177     37.232      0.000       6.259       6.957\n",
      "Explanatory Var #4      2.0725      0.011    189.896      0.000       2.051       2.094\n",
      "Explanatory Var #5     -0.7776      0.011    -68.372      0.000      -0.800      -0.755\n",
      "Explanatory Var #6      0.0124      0.008      1.595      0.111      -0.003       0.028\n",
      "Explanatory Var #7      0.0286      0.006      4.890      0.000       0.017       0.040\n",
      "Explanatory Var #8      0.3510      0.080      4.398      0.000       0.194       0.508\n",
      "Explanatory Var #9     -0.0293      0.010     -2.838      0.005      -0.050      -0.009\n",
      "Explanatory Var #10     0.1292      0.011     11.409      0.000       0.107       0.152\n",
      "Explanatory Var #11     0.0145      0.013      1.152      0.250      -0.010       0.039\n",
      "Explanatory Var #12     0.0752      0.009      8.698      0.000       0.058       0.092\n",
      "Explanatory Var #13     0.7414      0.177      4.198      0.000       0.394       1.089\n",
      "Explanatory Var #14    -0.0218      0.011     -1.974      0.049      -0.043   -8.61e-05\n",
      "Explanatory Var #15     0.1212      0.012     10.324      0.000       0.098       0.144\n",
      "==============================================================================\n",
      "Omnibus:                        0.087   Durbin-Watson:                   1.875\n",
      "Prob(Omnibus):                  0.957   Jarque-Bera (JB):                0.188\n",
      "Skew:                          -0.004   Prob(JB):                        0.910\n",
      "Kurtosis:                       2.897   Cond. No.                         287.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(gls_results.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependent Variable: The dependent variable is labeled as \"Dependent Var,\" and the analysis aims to explain its variation based on the independent variables.\n",
    "\n",
    "R-squared (uncentered): The uncentered R-squared is very high at 0.999, indicating that the independent variables, as a whole, explain 99.9% of the variation in the dependent variable. However, note that this R-squared is computed without centering because the model does not contain a constant.\n",
    "\n",
    "Adj. R-squared (uncentered): The uncentered adjusted R-squared is also very high at 0.999. This value takes into account the number of independent variables in the model while adjusting the R-squared.\n",
    "\n",
    "F-statistic: The F-statistic is used to test the overall significance of the GLS regression model. A high F-statistic, in this case, 4.509e+04, suggests that the model as a whole is statistically significant.\n",
    "\n",
    "Prob (F-statistic): The probability associated with the F-statistic is very low (0.00), indicating that the overall GLS model is highly statistically significant.\n",
    "\n",
    "No. Observations: There are 422 observations in the dataset.\n",
    "\n",
    "Degrees of Freedom (Df Residuals, Df Model):\n",
    "\n",
    "Df Residuals: 407 degrees of freedom for the residuals.\n",
    "\n",
    "Df Model: 15 degrees of freedom for the model.\n",
    "\n",
    "Covariance Type: The analysis was performed using a nonrobust covariance type.\n",
    "\n",
    "Coefficients (coef): The coefficients for each of the 15 explanatory variables (independent variables) are provided, along with their standard errors.\n",
    "\n",
    "t-statistic (t): The t-statistic measures the significance of each coefficient. A higher absolute t-value indicates greater significance.\n",
    "\n",
    "P>|t| (p-value): This represents the probability that the coefficient is not significantly different from zero. Low p-values (typically < 0.05) suggest that the corresponding variable is statistically significant in explaining the dependent variable.\n",
    "\n",
    "\n",
    "In summary, this GLS regression analysis indicates a highly significant model with a very high R-squared value. The coefficients and their associated statistics provide information about the individual explanatory variables' contributions to explaining the dependent variable. The provided information is quite similar to a standard OLS regression output, with the key difference being the use of GLS regression instead of OLS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tSplit the dataset into two as the training and test sets (test size = 0.5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tRun the Lasso model with alpha=1 and estimate the coefficients using the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.26972628,  1.68394638,  2.02626245,  2.08756512, -0.91746375,\n",
       "       -0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.01314162,  0.        , -0.        ,  0.        , -0.03617731])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lasso = lm.Lasso(alpha=1).fit(X_train,y_train)\n",
    "model_lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tThen, calculate the mean absolute percentage error using the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_percentage_errors = abs((y_test - predictions) / y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = absolute_percentage_errors.mean()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE): 4.432190198291583\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE): 4.432190198291583\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "mape = mape*100\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\tFind an approximate value for alpha that minimizes the mean absolute percentage error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE) for Alpha 0.01: 0.04429881163345532\n"
     ]
    }
   ],
   "source": [
    "model_lasso = lm.Lasso(alpha=0.01).fit(X_train,y_train)\n",
    "model_lasso.coef_\n",
    "\n",
    "predictions = model_lasso.predict(X_test)\n",
    "absolute_percentage_errors = abs((y_test - predictions) / y_test) * 100\n",
    "mape = absolute_percentage_errors.mean()    \n",
    "print(\"Mean Absolute Percentage Error (MAPE) for Alpha 0.01:\", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE) for Alpha 0.1: 0.44323186549579874\n"
     ]
    }
   ],
   "source": [
    "model_lasso = lm.Lasso(alpha=0.1).fit(X_train,y_train)\n",
    "model_lasso.coef_\n",
    "\n",
    "predictions = model_lasso.predict(X_test)\n",
    "absolute_percentage_errors = abs((y_test - predictions) / y_test) * 100\n",
    "mape = absolute_percentage_errors.mean()    \n",
    "print(\"Mean Absolute Percentage Error (MAPE) for Alpha 0.1:\", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE) for Alpha 10: 8.587094351590437\n"
     ]
    }
   ],
   "source": [
    "model_lasso = lm.Lasso(alpha=10).fit(X_train,y_train)\n",
    "model_lasso.coef_\n",
    "\n",
    "predictions = model_lasso.predict(X_test)\n",
    "absolute_percentage_errors = abs((y_test - predictions) / y_test) * 100\n",
    "mape = absolute_percentage_errors.mean()    \n",
    "print(\"Mean Absolute Percentage Error (MAPE) for Alpha 10:\", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE) for Alpha 100: 44.287702093738424\n"
     ]
    }
   ],
   "source": [
    "model_lasso = lm.Lasso(alpha=100).fit(X_train,y_train)\n",
    "model_lasso.coef_\n",
    "\n",
    "predictions = model_lasso.predict(X_test)\n",
    "absolute_percentage_errors = abs((y_test - predictions) / y_test) * 100\n",
    "mape = absolute_percentage_errors.mean()    \n",
    "print(\"Mean Absolute Percentage Error (MAPE) for Alpha 100:\", mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Percentage Error (MAPE) for Alpha 0.01: 0.04429881163345532\n",
    "\n",
    "Mean Absolute Percentage Error (MAPE) for Alpha 0.1: 0.44323186549579874\n",
    "\n",
    "Mean Absolute Percentage Error (MAPE) for Alpha 1: 4.432190198291583\n",
    "\n",
    "Mean Absolute Percentage Error (MAPE) for Alpha 10: 8.587094351590437\n",
    "\n",
    "Mean Absolute Percentage Error (MAPE) for Alpha 100: 44.287702093738424"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tUse the demand data given in the table and develop an appropriate forecasting model (i.e., the tailored regularization discussed in the class—see your slides for more info) that exploits the available information given in the table as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]\n",
    "Demand = [100, 112, 107, 103, 91, 85, 84, 85, 79, 81, 134, 86, 99, 89, 111, 114, 118, 163, 193, 143, 144, 202, 158, 160, 144]\n",
    "Adv_Demand = [71, 30, 75, 64, 41, 51, 42, 51, 57, 49, 134, 52, 99, 56, 81, 79, 73, 163, 193, 99, 91, 202, 105, 101, 96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>Demand</th>\n",
       "      <th>Adv_Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>91</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>84</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>85</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>81</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>86</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>89</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>111</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>114</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>118</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>143</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>144</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>160</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>144</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  Demand  Adv_Demand\n",
       "0       1     100          71\n",
       "1       2     112          30\n",
       "2       3     107          75\n",
       "3       4     103          64\n",
       "4       5      91          41\n",
       "5       6      85          51\n",
       "6       7      84          42\n",
       "7       8      85          51\n",
       "8       9      79          57\n",
       "9      10      81          49\n",
       "10     11     134         134\n",
       "11     12      86          52\n",
       "12     13      99          99\n",
       "13     14      89          56\n",
       "14     15     111          81\n",
       "15     16     114          79\n",
       "16     17     118          73\n",
       "17     18     163         163\n",
       "18     19     193         193\n",
       "19     20     143          99\n",
       "20     21     144          91\n",
       "21     22     202         202\n",
       "22     23     158         105\n",
       "23     24     160         101\n",
       "24     25     144          96"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast = pd.DataFrame({'month': month, 'Demand': Demand, 'Adv_Demand': Adv_Demand})\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasted Demand: [126.09920919]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Sample data for your DataFrame\n",
    "month = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]\n",
    "Demand = [100, 112, 107, 103, 91, 85, 84, 85, 79, 81, 134, 86, 99, 89, 111, 114, 118, 163, 193, 143, 144, 202, 158, 160, 144]\n",
    "Adv_Demand = [71, 30, 75, 64, 41, 51, 42, 51, 57, 49, 134, 52, 99, 56, 81, 79, 73, 163, 193, 99, 91, 202, 105, 101, 96]\n",
    "\n",
    "# Create a DataFrame with the given data\n",
    "data = {\n",
    "    'month': month,\n",
    "    'Demand': Demand,\n",
    "    'Adv_Demand': Adv_Demand,\n",
    "}\n",
    "forecast = pd.DataFrame(data)\n",
    "\n",
    "# Prepare the data\n",
    "X = forecast[['month', 'Adv_Demand']]  # Adjust the column names accordingly\n",
    "Y = forecast['Demand']\n",
    "\n",
    "# Initialize and fit a Ridge regression model\n",
    "alpha = 1.0  # You can adjust the regularization strength as needed\n",
    "ridge_model = Ridge(alpha=alpha)\n",
    "ridge_model.fit(X, Y)\n",
    "\n",
    "# Predict future demand\n",
    "future_X = np.array([[6, 115]])  # Adjust these values for your specific forecast\n",
    "forecasted_demand = ridge_model.predict(future_X)\n",
    "\n",
    "print(\"Forecasted Demand:\", forecasted_demand)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result \"Forecasted Demand: [149.88505747]\" is the output of your Ridge regression model, representing the forecasted or predicted demand for a specific set of input variables. \n",
    "\n",
    "Forecasted Demand: This is the predicted value for the demand, which is what we are trying to forecast. In this case, the model estimates that the demand will be approximately 149.89 units.\n",
    "\n",
    "Interpretation: The forecasted demand of approximately 149.89 units is based on the input variables used to make the prediction, which are 'month' and 'Adv_Demand' in this case. This means that, given a 'month' value of 6 and an 'Adv_Demand' value of 115 (as specified in your 'future_X' array), the model predicts that the demand will be around 149.89 units.\n",
    "\n",
    "Confidence: The forecasted value is not an absolute truth but a statistical estimate. The actual demand may vary, and the accuracy of the prediction depends on the quality of the data, the model's assumptions, and other factors. To assess the reliability of the forecast, we will use metrics like mean squared error (MSE) or root mean squared error (RMSE) to measure the model's prediction accuracy when compared to actual historical data.\n",
    "\n",
    "In summary, the result \"Forecasted Demand: [149.88505747]\" is the model's best estimate of the demand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tInterpret your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso RMSE: 13.674863351909064\n",
      "Ridge RMSE: 13.674350201193812\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame for the data\n",
    "data = pd.DataFrame({'Month':     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25],\n",
    "                    'Demand':     [100, 112, 107, 103, 91, 85, 84, 85, 79, 81, 134, 86, 99, 89, 111, 114, 118, 163, 193, 143, 144, 202, 158, 160, 144],\n",
    "                    'Adv_Demand': [71, 30, 75, 64, 41, 51, 42, 51, 57, 49, 134, 52, 99, 56, 81, 79, 73, 163, 193, 99, 91, 202, 105, 101, 96]})\n",
    "\n",
    "# Machine Learning Model\n",
    "X = data[['Month', 'Adv_Demand']]\n",
    "y = data['Demand']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Lasso Regularization\n",
    "lasso_model = Lasso(alpha=0.01)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Ridge Regularization\n",
    "ridge_model = Ridge(alpha=0.01)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the models\n",
    "lasso_predictions = lasso_model.predict(X_test)\n",
    "ridge_predictions = ridge_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "lasso_rmse = sqrt(mean_squared_error(y_test, lasso_predictions))\n",
    "ridge_rmse = sqrt(mean_squared_error(y_test, ridge_predictions))\n",
    "\n",
    "# Print RMSE for each model\n",
    "print(f'Lasso RMSE: {lasso_rmse}')\n",
    "print(f'Ridge RMSE: {ridge_rmse}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
