{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sl\n",
    "import matplotlib as mp\n",
    "import scipy as cp\n",
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
    "from sklearn.metrics import f1_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from math import sqrt\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.linalg import toeplitz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tDownload the “dataset_lm.csv” file from Canvas and upload it to Jupyter Notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\johns\\OneDrive\\Desktop\\MBAN Semester 2\\Predictive Analytics\\Assignment 1\\dataset_lm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a quick overview of the data through the use of the head and info function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependent Var</th>\n",
       "      <th>Explanatory Var #1</th>\n",
       "      <th>Explanatory Var #2</th>\n",
       "      <th>Explanatory Var #3</th>\n",
       "      <th>Explanatory Var #4</th>\n",
       "      <th>Explanatory Var #5</th>\n",
       "      <th>Explanatory Var #6</th>\n",
       "      <th>Explanatory Var #7</th>\n",
       "      <th>Explanatory Var #8</th>\n",
       "      <th>Explanatory Var #9</th>\n",
       "      <th>Explanatory Var #10</th>\n",
       "      <th>Explanatory Var #11</th>\n",
       "      <th>Explanatory Var #12</th>\n",
       "      <th>Explanatory Var #13</th>\n",
       "      <th>Explanatory Var #14</th>\n",
       "      <th>Explanatory Var #15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.293458</td>\n",
       "      <td>13.698667</td>\n",
       "      <td>50.639873</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.568035</td>\n",
       "      <td>45.121911</td>\n",
       "      <td>11.412501</td>\n",
       "      <td>56.410757</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.281132</td>\n",
       "      <td>38.996909</td>\n",
       "      <td>-3.010548</td>\n",
       "      <td>49.195073</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.153143</td>\n",
       "      <td>46.919314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.473431</td>\n",
       "      <td>2.714725</td>\n",
       "      <td>65.845845</td>\n",
       "      <td>1</td>\n",
       "      <td>-25.105932</td>\n",
       "      <td>47.190213</td>\n",
       "      <td>10.080280</td>\n",
       "      <td>65.383107</td>\n",
       "      <td>3</td>\n",
       "      <td>-36.763585</td>\n",
       "      <td>51.654939</td>\n",
       "      <td>4.991111</td>\n",
       "      <td>45.591729</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.474403</td>\n",
       "      <td>53.383508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.195330</td>\n",
       "      <td>11.618072</td>\n",
       "      <td>65.072497</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.897464</td>\n",
       "      <td>52.163036</td>\n",
       "      <td>11.057301</td>\n",
       "      <td>82.812717</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.733547</td>\n",
       "      <td>48.913837</td>\n",
       "      <td>-2.457696</td>\n",
       "      <td>56.608806</td>\n",
       "      <td>0</td>\n",
       "      <td>-27.903299</td>\n",
       "      <td>48.515026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.074583</td>\n",
       "      <td>0.818623</td>\n",
       "      <td>45.408996</td>\n",
       "      <td>1</td>\n",
       "      <td>-18.316132</td>\n",
       "      <td>54.356714</td>\n",
       "      <td>5.029029</td>\n",
       "      <td>48.812471</td>\n",
       "      <td>1</td>\n",
       "      <td>-12.825591</td>\n",
       "      <td>45.851732</td>\n",
       "      <td>14.974177</td>\n",
       "      <td>47.362594</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.064411</td>\n",
       "      <td>55.266254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86.035569</td>\n",
       "      <td>9.077544</td>\n",
       "      <td>73.548021</td>\n",
       "      <td>0</td>\n",
       "      <td>-19.204165</td>\n",
       "      <td>47.186807</td>\n",
       "      <td>12.128134</td>\n",
       "      <td>62.520911</td>\n",
       "      <td>2</td>\n",
       "      <td>-13.804860</td>\n",
       "      <td>47.765904</td>\n",
       "      <td>9.593982</td>\n",
       "      <td>53.700562</td>\n",
       "      <td>0</td>\n",
       "      <td>-17.546302</td>\n",
       "      <td>48.150543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dependent Var  Explanatory Var #1  Explanatory Var #2  Explanatory Var #3  \\\n",
       "0      56.293458           13.698667           50.639873                   0   \n",
       "1      58.473431            2.714725           65.845845                   1   \n",
       "2      94.195330           11.618072           65.072497                   0   \n",
       "3      29.074583            0.818623           45.408996                   1   \n",
       "4      86.035569            9.077544           73.548021                   0   \n",
       "\n",
       "   Explanatory Var #4  Explanatory Var #5  Explanatory Var #6  \\\n",
       "0          -18.568035           45.121911           11.412501   \n",
       "1          -25.105932           47.190213           10.080280   \n",
       "2           -7.897464           52.163036           11.057301   \n",
       "3          -18.316132           54.356714            5.029029   \n",
       "4          -19.204165           47.186807           12.128134   \n",
       "\n",
       "   Explanatory Var #7  Explanatory Var #8  Explanatory Var #9  \\\n",
       "0           56.410757                   2          -12.281132   \n",
       "1           65.383107                   3          -36.763585   \n",
       "2           82.812717                   0          -15.733547   \n",
       "3           48.812471                   1          -12.825591   \n",
       "4           62.520911                   2          -13.804860   \n",
       "\n",
       "   Explanatory Var #10  Explanatory Var #11  Explanatory Var #12  \\\n",
       "0            38.996909            -3.010548            49.195073   \n",
       "1            51.654939             4.991111            45.591729   \n",
       "2            48.913837            -2.457696            56.608806   \n",
       "3            45.851732            14.974177            47.362594   \n",
       "4            47.765904             9.593982            53.700562   \n",
       "\n",
       "   Explanatory Var #13  Explanatory Var #14  Explanatory Var #15  \n",
       "0                    0           -21.153143            46.919314  \n",
       "1                    0            -6.474403            53.383508  \n",
       "2                    0           -27.903299            48.515026  \n",
       "3                    1           -10.064411            55.266254  \n",
       "4                    0           -17.546302            48.150543  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422 entries, 0 to 421\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Dependent Var        422 non-null    float64\n",
      " 1   Explanatory Var #1   422 non-null    float64\n",
      " 2   Explanatory Var #2   422 non-null    float64\n",
      " 3   Explanatory Var #3   422 non-null    int64  \n",
      " 4   Explanatory Var #4   422 non-null    float64\n",
      " 5   Explanatory Var #5   422 non-null    float64\n",
      " 6   Explanatory Var #6   422 non-null    float64\n",
      " 7   Explanatory Var #7   422 non-null    float64\n",
      " 8   Explanatory Var #8   422 non-null    int64  \n",
      " 9   Explanatory Var #9   422 non-null    float64\n",
      " 10  Explanatory Var #10  422 non-null    float64\n",
      " 11  Explanatory Var #11  422 non-null    float64\n",
      " 12  Explanatory Var #12  422 non-null    float64\n",
      " 13  Explanatory Var #13  422 non-null    int64  \n",
      " 14  Explanatory Var #14  422 non-null    float64\n",
      " 15  Explanatory Var #15  422 non-null    float64\n",
      "dtypes: float64(13), int64(3)\n",
      "memory usage: 52.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tRun the OLS model by using the dependent and explanatory variables in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set y to the target variable Dependent Var\n",
    "\n",
    "Set X all of the explanatory variables by setting it to the entire dataset except the Dependent Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Dependent Var']\n",
    "X = df.drop('Dependent Var', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we created a regular model using the X and y created above. However, in the notes the model says that it would center if a constant was added.\n",
    "\n",
    "Next, we added a constant to the X value then created the updated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg = sm.OLS(y,X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_updated = sm.add_constant(X)\n",
    "model_updated = sm.OLS(y,x_updated).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tShow your summary table in Python and interpret your results in the summary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Dependent Var</td>  <th>  R-squared (uncentered):</th>      <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>4.509e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 28 Oct 2023</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:50:16</td>     <th>  Log-Likelihood:    </th>          <td> -841.76</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   422</td>      <th>  AIC:               </th>          <td>   1714.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   407</td>      <th>  BIC:               </th>          <td>   1774.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #1</th>  <td>    1.3078</td> <td>    0.013</td> <td>  102.159</td> <td> 0.000</td> <td>    1.283</td> <td>    1.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #2</th>  <td>    1.7667</td> <td>    0.009</td> <td>  203.101</td> <td> 0.000</td> <td>    1.750</td> <td>    1.784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #3</th>  <td>    6.6083</td> <td>    0.177</td> <td>   37.232</td> <td> 0.000</td> <td>    6.259</td> <td>    6.957</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #4</th>  <td>    2.0725</td> <td>    0.011</td> <td>  189.896</td> <td> 0.000</td> <td>    2.051</td> <td>    2.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #5</th>  <td>   -0.7776</td> <td>    0.011</td> <td>  -68.372</td> <td> 0.000</td> <td>   -0.800</td> <td>   -0.755</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #6</th>  <td>    0.0124</td> <td>    0.008</td> <td>    1.595</td> <td> 0.111</td> <td>   -0.003</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #7</th>  <td>    0.0286</td> <td>    0.006</td> <td>    4.890</td> <td> 0.000</td> <td>    0.017</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #8</th>  <td>    0.3510</td> <td>    0.080</td> <td>    4.398</td> <td> 0.000</td> <td>    0.194</td> <td>    0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #9</th>  <td>   -0.0293</td> <td>    0.010</td> <td>   -2.838</td> <td> 0.005</td> <td>   -0.050</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #10</th> <td>    0.1292</td> <td>    0.011</td> <td>   11.409</td> <td> 0.000</td> <td>    0.107</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #11</th> <td>    0.0145</td> <td>    0.013</td> <td>    1.152</td> <td> 0.250</td> <td>   -0.010</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #12</th> <td>    0.0752</td> <td>    0.009</td> <td>    8.698</td> <td> 0.000</td> <td>    0.058</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #13</th> <td>    0.7414</td> <td>    0.177</td> <td>    4.198</td> <td> 0.000</td> <td>    0.394</td> <td>    1.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #14</th> <td>   -0.0218</td> <td>    0.011</td> <td>   -1.974</td> <td> 0.049</td> <td>   -0.043</td> <td>-8.61e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #15</th> <td>    0.1212</td> <td>    0.012</td> <td>   10.324</td> <td> 0.000</td> <td>    0.098</td> <td>    0.144</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.087</td> <th>  Durbin-Watson:     </th> <td>   1.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.957</td> <th>  Jarque-Bera (JB):  </th> <td>   0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.004</td> <th>  Prob(JB):          </th> <td>   0.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.897</td> <th>  Cond. No.          </th> <td>    287.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       &  Dependent Var   & \\textbf{  R-squared (uncentered):}      &     0.999   \\\\\n",
       "\\textbf{Model:}               &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.999   \\\\\n",
       "\\textbf{Method:}              &  Least Squares   & \\textbf{  F-statistic:       }          & 4.509e+04   \\\\\n",
       "\\textbf{Date:}                & Sat, 28 Oct 2023 & \\textbf{  Prob (F-statistic):}          &     0.00    \\\\\n",
       "\\textbf{Time:}                &     15:50:16     & \\textbf{  Log-Likelihood:    }          &   -841.76   \\\\\n",
       "\\textbf{No. Observations:}    &         422      & \\textbf{  AIC:               }          &     1714.   \\\\\n",
       "\\textbf{Df Residuals:}        &         407      & \\textbf{  BIC:               }          &     1774.   \\\\\n",
       "\\textbf{Df Model:}            &          15      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}     &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Explanatory Var \\#1}  &       1.3078  &        0.013     &   102.159  &         0.000        &        1.283    &        1.333     \\\\\n",
       "\\textbf{Explanatory Var \\#2}  &       1.7667  &        0.009     &   203.101  &         0.000        &        1.750    &        1.784     \\\\\n",
       "\\textbf{Explanatory Var \\#3}  &       6.6083  &        0.177     &    37.232  &         0.000        &        6.259    &        6.957     \\\\\n",
       "\\textbf{Explanatory Var \\#4}  &       2.0725  &        0.011     &   189.896  &         0.000        &        2.051    &        2.094     \\\\\n",
       "\\textbf{Explanatory Var \\#5}  &      -0.7776  &        0.011     &   -68.372  &         0.000        &       -0.800    &       -0.755     \\\\\n",
       "\\textbf{Explanatory Var \\#6}  &       0.0124  &        0.008     &     1.595  &         0.111        &       -0.003    &        0.028     \\\\\n",
       "\\textbf{Explanatory Var \\#7}  &       0.0286  &        0.006     &     4.890  &         0.000        &        0.017    &        0.040     \\\\\n",
       "\\textbf{Explanatory Var \\#8}  &       0.3510  &        0.080     &     4.398  &         0.000        &        0.194    &        0.508     \\\\\n",
       "\\textbf{Explanatory Var \\#9}  &      -0.0293  &        0.010     &    -2.838  &         0.005        &       -0.050    &       -0.009     \\\\\n",
       "\\textbf{Explanatory Var \\#10} &       0.1292  &        0.011     &    11.409  &         0.000        &        0.107    &        0.152     \\\\\n",
       "\\textbf{Explanatory Var \\#11} &       0.0145  &        0.013     &     1.152  &         0.250        &       -0.010    &        0.039     \\\\\n",
       "\\textbf{Explanatory Var \\#12} &       0.0752  &        0.009     &     8.698  &         0.000        &        0.058    &        0.092     \\\\\n",
       "\\textbf{Explanatory Var \\#13} &       0.7414  &        0.177     &     4.198  &         0.000        &        0.394    &        1.089     \\\\\n",
       "\\textbf{Explanatory Var \\#14} &      -0.0218  &        0.011     &    -1.974  &         0.049        &       -0.043    &    -8.61e-05     \\\\\n",
       "\\textbf{Explanatory Var \\#15} &       0.1212  &        0.012     &    10.324  &         0.000        &        0.098    &        0.144     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.087 & \\textbf{  Durbin-Watson:     } &    1.875  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.957 & \\textbf{  Jarque-Bera (JB):  } &    0.188  \\\\\n",
       "\\textbf{Skew:}          & -0.004 & \\textbf{  Prob(JB):          } &    0.910  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.897 & \\textbf{  Cond. No.          } &     287.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:          Dependent Var   R-squared (uncentered):                   0.999\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.999\n",
       "Method:                 Least Squares   F-statistic:                          4.509e+04\n",
       "Date:                Sat, 28 Oct 2023   Prob (F-statistic):                        0.00\n",
       "Time:                        15:50:16   Log-Likelihood:                         -841.76\n",
       "No. Observations:                 422   AIC:                                      1714.\n",
       "Df Residuals:                     407   BIC:                                      1774.\n",
       "Df Model:                          15                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "Explanatory Var #1      1.3078      0.013    102.159      0.000       1.283       1.333\n",
       "Explanatory Var #2      1.7667      0.009    203.101      0.000       1.750       1.784\n",
       "Explanatory Var #3      6.6083      0.177     37.232      0.000       6.259       6.957\n",
       "Explanatory Var #4      2.0725      0.011    189.896      0.000       2.051       2.094\n",
       "Explanatory Var #5     -0.7776      0.011    -68.372      0.000      -0.800      -0.755\n",
       "Explanatory Var #6      0.0124      0.008      1.595      0.111      -0.003       0.028\n",
       "Explanatory Var #7      0.0286      0.006      4.890      0.000       0.017       0.040\n",
       "Explanatory Var #8      0.3510      0.080      4.398      0.000       0.194       0.508\n",
       "Explanatory Var #9     -0.0293      0.010     -2.838      0.005      -0.050      -0.009\n",
       "Explanatory Var #10     0.1292      0.011     11.409      0.000       0.107       0.152\n",
       "Explanatory Var #11     0.0145      0.013      1.152      0.250      -0.010       0.039\n",
       "Explanatory Var #12     0.0752      0.009      8.698      0.000       0.058       0.092\n",
       "Explanatory Var #13     0.7414      0.177      4.198      0.000       0.394       1.089\n",
       "Explanatory Var #14    -0.0218      0.011     -1.974      0.049      -0.043   -8.61e-05\n",
       "Explanatory Var #15     0.1212      0.012     10.324      0.000       0.098       0.144\n",
       "==============================================================================\n",
       "Omnibus:                        0.087   Durbin-Watson:                   1.875\n",
       "Prob(Omnibus):                  0.957   Jarque-Bera (JB):                0.188\n",
       "Skew:                          -0.004   Prob(JB):                        0.910\n",
       "Kurtosis:                       2.897   Cond. No.                         287.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Dependent Var</td>  <th>  R-squared:         </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.488e+30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 28 Oct 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:50:16</td>     <th>  Log-Likelihood:    </th>  <td>  11995.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   422</td>      <th>  AIC:               </th> <td>-2.396e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   406</td>      <th>  BIC:               </th> <td>-2.389e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>   32.0000</td> <td> 9.77e-14</td> <td> 3.28e+14</td> <td> 0.000</td> <td>   32.000</td> <td>   32.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #1</th>  <td>    1.3000</td> <td> 7.89e-16</td> <td> 1.65e+15</td> <td> 0.000</td> <td>    1.300</td> <td>    1.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #2</th>  <td>    1.7000</td> <td> 5.73e-16</td> <td> 2.97e+15</td> <td> 0.000</td> <td>    1.700</td> <td>    1.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #3</th>  <td>    6.2000</td> <td>  1.1e-14</td> <td> 5.64e+14</td> <td> 0.000</td> <td>    6.200</td> <td>    6.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #4</th>  <td>    2.1000</td> <td> 6.77e-16</td> <td>  3.1e+15</td> <td> 0.000</td> <td>    2.100</td> <td>    2.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #5</th>  <td>   -0.9000</td> <td> 7.94e-16</td> <td>-1.13e+15</td> <td> 0.000</td> <td>   -0.900</td> <td>   -0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #6</th>  <td> 4.163e-16</td> <td> 4.79e-16</td> <td>    0.869</td> <td> 0.385</td> <td>-5.25e-16</td> <td> 1.36e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #7</th>  <td> 1.277e-15</td> <td>  3.7e-16</td> <td>    3.450</td> <td> 0.001</td> <td> 5.49e-16</td> <td>    2e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #8</th>  <td>-7.661e-15</td> <td> 5.03e-15</td> <td>   -1.523</td> <td> 0.128</td> <td>-1.75e-14</td> <td> 2.23e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #9</th>  <td>  7.72e-16</td> <td> 6.43e-16</td> <td>    1.201</td> <td> 0.231</td> <td>-4.92e-16</td> <td> 2.04e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #10</th> <td>-1.693e-15</td> <td> 8.01e-16</td> <td>   -2.113</td> <td> 0.035</td> <td>-3.27e-15</td> <td>-1.18e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #11</th> <td> 2.404e-15</td> <td> 7.75e-16</td> <td>    3.103</td> <td> 0.002</td> <td> 8.81e-16</td> <td> 3.93e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #12</th> <td>-1.429e-15</td> <td>  5.8e-16</td> <td>   -2.465</td> <td> 0.014</td> <td>-2.57e-15</td> <td> -2.9e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #13</th> <td>-1.155e-14</td> <td> 1.11e-14</td> <td>   -1.039</td> <td> 0.299</td> <td>-3.34e-14</td> <td> 1.03e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #14</th> <td>-2.998e-15</td> <td> 6.82e-16</td> <td>   -4.396</td> <td> 0.000</td> <td>-4.34e-15</td> <td>-1.66e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #15</th> <td>-3.664e-15</td> <td> 8.12e-16</td> <td>   -4.512</td> <td> 0.000</td> <td>-5.26e-15</td> <td>-2.07e-15</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.418</td> <th>  Durbin-Watson:     </th> <td>   0.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.811</td> <th>  Jarque-Bera (JB):  </th> <td>   0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.007</td> <th>  Prob(JB):          </th> <td>   0.887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.116</td> <th>  Cond. No.          </th> <td>2.55e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.55e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       &  Dependent Var   & \\textbf{  R-squared:         } &     1.000   \\\\\n",
       "\\textbf{Model:}               &       OLS        & \\textbf{  Adj. R-squared:    } &     1.000   \\\\\n",
       "\\textbf{Method:}              &  Least Squares   & \\textbf{  F-statistic:       } & 1.488e+30   \\\\\n",
       "\\textbf{Date:}                & Sat, 28 Oct 2023 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                &     15:50:16     & \\textbf{  Log-Likelihood:    } &    11995.   \\\\\n",
       "\\textbf{No. Observations:}    &         422      & \\textbf{  AIC:               } & -2.396e+04  \\\\\n",
       "\\textbf{Df Residuals:}        &         406      & \\textbf{  BIC:               } & -2.389e+04  \\\\\n",
       "\\textbf{Df Model:}            &          15      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}     &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                &      32.0000  &     9.77e-14     &  3.28e+14  &         0.000        &       32.000    &       32.000     \\\\\n",
       "\\textbf{Explanatory Var \\#1}  &       1.3000  &     7.89e-16     &  1.65e+15  &         0.000        &        1.300    &        1.300     \\\\\n",
       "\\textbf{Explanatory Var \\#2}  &       1.7000  &     5.73e-16     &  2.97e+15  &         0.000        &        1.700    &        1.700     \\\\\n",
       "\\textbf{Explanatory Var \\#3}  &       6.2000  &      1.1e-14     &  5.64e+14  &         0.000        &        6.200    &        6.200     \\\\\n",
       "\\textbf{Explanatory Var \\#4}  &       2.1000  &     6.77e-16     &   3.1e+15  &         0.000        &        2.100    &        2.100     \\\\\n",
       "\\textbf{Explanatory Var \\#5}  &      -0.9000  &     7.94e-16     & -1.13e+15  &         0.000        &       -0.900    &       -0.900     \\\\\n",
       "\\textbf{Explanatory Var \\#6}  &    4.163e-16  &     4.79e-16     &     0.869  &         0.385        &    -5.25e-16    &     1.36e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#7}  &    1.277e-15  &      3.7e-16     &     3.450  &         0.001        &     5.49e-16    &        2e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#8}  &   -7.661e-15  &     5.03e-15     &    -1.523  &         0.128        &    -1.75e-14    &     2.23e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#9}  &     7.72e-16  &     6.43e-16     &     1.201  &         0.231        &    -4.92e-16    &     2.04e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#10} &   -1.693e-15  &     8.01e-16     &    -2.113  &         0.035        &    -3.27e-15    &    -1.18e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#11} &    2.404e-15  &     7.75e-16     &     3.103  &         0.002        &     8.81e-16    &     3.93e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#12} &   -1.429e-15  &      5.8e-16     &    -2.465  &         0.014        &    -2.57e-15    &     -2.9e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#13} &   -1.155e-14  &     1.11e-14     &    -1.039  &         0.299        &    -3.34e-14    &     1.03e-14     \\\\\n",
       "\\textbf{Explanatory Var \\#14} &   -2.998e-15  &     6.82e-16     &    -4.396  &         0.000        &    -4.34e-15    &    -1.66e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#15} &   -3.664e-15  &     8.12e-16     &    -4.512  &         0.000        &    -5.26e-15    &    -2.07e-15     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.418 & \\textbf{  Durbin-Watson:     } &    0.650  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.811 & \\textbf{  Jarque-Bera (JB):  } &    0.241  \\\\\n",
       "\\textbf{Skew:}          &  0.007 & \\textbf{  Prob(JB):          } &    0.887  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.116 & \\textbf{  Cond. No.          } & 2.55e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.55e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          Dependent Var   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 1.488e+30\n",
       "Date:                Sat, 28 Oct 2023   Prob (F-statistic):               0.00\n",
       "Time:                        15:50:16   Log-Likelihood:                 11995.\n",
       "No. Observations:                 422   AIC:                        -2.396e+04\n",
       "Df Residuals:                     406   BIC:                        -2.389e+04\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                  32.0000   9.77e-14   3.28e+14      0.000      32.000      32.000\n",
       "Explanatory Var #1      1.3000   7.89e-16   1.65e+15      0.000       1.300       1.300\n",
       "Explanatory Var #2      1.7000   5.73e-16   2.97e+15      0.000       1.700       1.700\n",
       "Explanatory Var #3      6.2000    1.1e-14   5.64e+14      0.000       6.200       6.200\n",
       "Explanatory Var #4      2.1000   6.77e-16    3.1e+15      0.000       2.100       2.100\n",
       "Explanatory Var #5     -0.9000   7.94e-16  -1.13e+15      0.000      -0.900      -0.900\n",
       "Explanatory Var #6   4.163e-16   4.79e-16      0.869      0.385   -5.25e-16    1.36e-15\n",
       "Explanatory Var #7   1.277e-15    3.7e-16      3.450      0.001    5.49e-16       2e-15\n",
       "Explanatory Var #8  -7.661e-15   5.03e-15     -1.523      0.128   -1.75e-14    2.23e-15\n",
       "Explanatory Var #9    7.72e-16   6.43e-16      1.201      0.231   -4.92e-16    2.04e-15\n",
       "Explanatory Var #10 -1.693e-15   8.01e-16     -2.113      0.035   -3.27e-15   -1.18e-16\n",
       "Explanatory Var #11  2.404e-15   7.75e-16      3.103      0.002    8.81e-16    3.93e-15\n",
       "Explanatory Var #12 -1.429e-15    5.8e-16     -2.465      0.014   -2.57e-15    -2.9e-16\n",
       "Explanatory Var #13 -1.155e-14   1.11e-14     -1.039      0.299   -3.34e-14    1.03e-14\n",
       "Explanatory Var #14 -2.998e-15   6.82e-16     -4.396      0.000   -4.34e-15   -1.66e-15\n",
       "Explanatory Var #15 -3.664e-15   8.12e-16     -4.512      0.000   -5.26e-15   -2.07e-15\n",
       "==============================================================================\n",
       "Omnibus:                        0.418   Durbin-Watson:                   0.650\n",
       "Prob(Omnibus):                  0.811   Jarque-Bera (JB):                0.241\n",
       "Skew:                           0.007   Prob(JB):                        0.887\n",
       "Kurtosis:                       3.116   Cond. No.                     2.55e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.55e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_updated.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets remove values that have a p-value greater than 0.05 as this tells us these values are not significantly different from 0\n",
    "\n",
    "I kept removing variables until I was left with no variables with a p-value greater than 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal 1\n",
    "x_updated = x_updated.drop(\"Explanatory Var #6\", axis = 1)\n",
    "x_updated = x_updated.drop(\"Explanatory Var #8\", axis = 1)\n",
    "x_updated = x_updated.drop(\"Explanatory Var #9\", axis = 1)\n",
    "x_updated = x_updated.drop(\"Explanatory Var #13\", axis = 1)\n",
    "\n",
    "# Removal 2\n",
    "x_updated = x_updated.drop(\"Explanatory Var #11\", axis = 1)\n",
    "x_updated = x_updated.drop(\"Explanatory Var #12\", axis = 1)\n",
    "x_updated = x_updated.drop(\"Explanatory Var #15\", axis = 1)\n",
    "\n",
    "# Removal 3\n",
    "x_updated = x_updated.drop(\"Explanatory Var #7\", axis = 1)\n",
    "x_updated = x_updated.drop(\"Explanatory Var #10\", axis = 1)\n",
    "x_updated = x_updated.drop(\"Explanatory Var #14\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Dependent Var</td>  <th>  R-squared:         </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>3.870e+31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 28 Oct 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:50:16</td>     <th>  Log-Likelihood:    </th>  <td>  12446.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   422</td>      <th>  AIC:               </th> <td>-2.488e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   416</td>      <th>  BIC:               </th> <td>-2.486e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>   32.0000</td> <td>  1.8e-14</td> <td> 1.78e+15</td> <td> 0.000</td> <td>   32.000</td> <td>   32.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #1</th> <td>    1.3000</td> <td> 2.65e-16</td> <td>  4.9e+15</td> <td> 0.000</td> <td>    1.300</td> <td>    1.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #2</th> <td>    1.7000</td> <td> 1.93e-16</td> <td>  8.8e+15</td> <td> 0.000</td> <td>    1.700</td> <td>    1.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #3</th> <td>    6.2000</td> <td> 3.69e-15</td> <td> 1.68e+15</td> <td> 0.000</td> <td>    6.200</td> <td>    6.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #4</th> <td>    2.1000</td> <td> 2.29e-16</td> <td> 9.18e+15</td> <td> 0.000</td> <td>    2.100</td> <td>    2.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #5</th> <td>   -0.9000</td> <td> 2.65e-16</td> <td>-3.39e+15</td> <td> 0.000</td> <td>   -0.900</td> <td>   -0.900</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.824</td> <th>  Durbin-Watson:     </th> <td>   1.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.148</td> <th>  Jarque-Bera (JB):  </th> <td>   2.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.017</td> <th>  Prob(JB):          </th> <td>   0.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.602</td> <th>  Cond. No.          </th> <td>    785.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}      &  Dependent Var   & \\textbf{  R-squared:         } &     1.000   \\\\\n",
       "\\textbf{Model:}              &       OLS        & \\textbf{  Adj. R-squared:    } &     1.000   \\\\\n",
       "\\textbf{Method:}             &  Least Squares   & \\textbf{  F-statistic:       } & 3.870e+31   \\\\\n",
       "\\textbf{Date:}               & Sat, 28 Oct 2023 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}               &     15:50:16     & \\textbf{  Log-Likelihood:    } &    12446.   \\\\\n",
       "\\textbf{No. Observations:}   &         422      & \\textbf{  AIC:               } & -2.488e+04  \\\\\n",
       "\\textbf{Df Residuals:}       &         416      & \\textbf{  BIC:               } & -2.486e+04  \\\\\n",
       "\\textbf{Df Model:}           &           5      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}    &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                             & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}               &      32.0000  &      1.8e-14     &  1.78e+15  &         0.000        &       32.000    &       32.000     \\\\\n",
       "\\textbf{Explanatory Var \\#1} &       1.3000  &     2.65e-16     &   4.9e+15  &         0.000        &        1.300    &        1.300     \\\\\n",
       "\\textbf{Explanatory Var \\#2} &       1.7000  &     1.93e-16     &   8.8e+15  &         0.000        &        1.700    &        1.700     \\\\\n",
       "\\textbf{Explanatory Var \\#3} &       6.2000  &     3.69e-15     &  1.68e+15  &         0.000        &        6.200    &        6.200     \\\\\n",
       "\\textbf{Explanatory Var \\#4} &       2.1000  &     2.29e-16     &  9.18e+15  &         0.000        &        2.100    &        2.100     \\\\\n",
       "\\textbf{Explanatory Var \\#5} &      -0.9000  &     2.65e-16     & -3.39e+15  &         0.000        &       -0.900    &       -0.900     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  3.824 & \\textbf{  Durbin-Watson:     } &    1.371  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.148 & \\textbf{  Jarque-Bera (JB):  } &    2.806  \\\\\n",
       "\\textbf{Skew:}          & -0.017 & \\textbf{  Prob(JB):          } &    0.246  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.602 & \\textbf{  Cond. No.          } &     785.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          Dependent Var   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 3.870e+31\n",
       "Date:                Sat, 28 Oct 2023   Prob (F-statistic):               0.00\n",
       "Time:                        15:50:16   Log-Likelihood:                 12446.\n",
       "No. Observations:                 422   AIC:                        -2.488e+04\n",
       "Df Residuals:                     416   BIC:                        -2.486e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                 32.0000    1.8e-14   1.78e+15      0.000      32.000      32.000\n",
       "Explanatory Var #1     1.3000   2.65e-16    4.9e+15      0.000       1.300       1.300\n",
       "Explanatory Var #2     1.7000   1.93e-16    8.8e+15      0.000       1.700       1.700\n",
       "Explanatory Var #3     6.2000   3.69e-15   1.68e+15      0.000       6.200       6.200\n",
       "Explanatory Var #4     2.1000   2.29e-16   9.18e+15      0.000       2.100       2.100\n",
       "Explanatory Var #5    -0.9000   2.65e-16  -3.39e+15      0.000      -0.900      -0.900\n",
       "==============================================================================\n",
       "Omnibus:                        3.824   Durbin-Watson:                   1.371\n",
       "Prob(Omnibus):                  0.148   Jarque-Bera (JB):                2.806\n",
       "Skew:                          -0.017   Prob(JB):                        0.246\n",
       "Kurtosis:                       2.602   Cond. No.                         785.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_updated = sm.OLS(y,x_updated).fit()\n",
    "model_updated.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared and adjusted R-squared: 1.000 meaning that the independent variables explain all of the variation in the dependent variable\n",
    "\n",
    "F-Statistic: 3.870e+31 is a very high value meaning the model is statistically significant\n",
    "\n",
    "Prob(F-statistic): 0 is a very low value meaning the overall model is statistically significant\n",
    "\n",
    "Coefficients (Constant): 32 meaning when all other values have a value of 0, the dependent variable would have a value of 32\n",
    "\n",
    "Coefficients (Explanatory Variables): All of the explanatory variables have unique coefficients that would affect the model in their own unique way\n",
    "\n",
    "t-statistic: tells us how significant each of the explanantory variables are, the farther from 0 the more significant. All of our values have very high or very low t-statistic values.\n",
    "\n",
    "p-value: tells us the probaility that coeficients are not significantly different from 0, we have only kept the variables that have had a p-value less than 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tUse error values from the OLS model to calculate their standard deviation and autocorrelation values for the first three lags. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the error values we will first get the predicted values\n",
    "\n",
    "Then subtract the predicted values from the actual values to get the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.421085e-14\n",
       "1     -2.842171e-14\n",
       "2      7.105427e-14\n",
       "3      3.552714e-14\n",
       "4      2.842171e-14\n",
       "           ...     \n",
       "417   -1.421085e-14\n",
       "418    4.263256e-14\n",
       "419   -7.105427e-15\n",
       "420    1.421085e-14\n",
       "421    7.105427e-15\n",
       "Length: 422, dtype: float64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_vals = model_updated.predict(x_updated)\n",
    "errors = y - pred_vals\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then used the standard deviation function (std) to calculate the standard deviation of the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.154798854246503e-14"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_dev = np.std(errors)\n",
    "st_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the autocorrelation for the first three values using the built in autocorrelation function (acf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025730176015300463\n",
      "0.0719423706866769\n",
      "-0.030938373917480142\n"
     ]
    }
   ],
   "source": [
    "autocorrelation = acf(errors, nlags=3)\n",
    "\n",
    "ac1 = autocorrelation[1]\n",
    "ac2 = autocorrelation[2]\n",
    "ac3 = autocorrelation[3]\n",
    "\n",
    "print(ac1)\n",
    "print(ac2)\n",
    "print(ac3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tThen, run the GLS model accordingly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first must build the covariance matrix using the values we have generated\n",
    "\n",
    "The first is the standard deviation of the errors which was generated above\n",
    "\n",
    "Next we use the the number one then the three autocorrelation values and put that into a list together\n",
    "\n",
    "We finally set all of the remaining values to zero which is 418 in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = st_dev**2*toeplitz(np.append([1, ac1, ac2, ac3], np.zeros(418)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "gls_results = sm.GLS(y, x_updated, cov_matrix).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tShow your summary table in Python and interpret your results in the summary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            GLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          Dependent Var   R-squared:                       1.000\n",
      "Model:                            GLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 2.671e+31\n",
      "Date:                Sat, 28 Oct 2023   Prob (F-statistic):               0.00\n",
      "Time:                        15:50:17   Log-Likelihood:                 12364.\n",
      "No. Observations:                 422   AIC:                        -2.472e+04\n",
      "Df Residuals:                     416   BIC:                        -2.469e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                 32.0000   2.19e-14   1.46e+15      0.000      32.000      32.000\n",
      "Explanatory Var #1     1.3000    3.2e-16   4.06e+15      0.000       1.300       1.300\n",
      "Explanatory Var #2     1.7000   2.33e-16   7.28e+15      0.000       1.700       1.700\n",
      "Explanatory Var #3     6.2000   4.47e-15   1.39e+15      0.000       6.200       6.200\n",
      "Explanatory Var #4     2.1000   2.77e-16   7.59e+15      0.000       2.100       2.100\n",
      "Explanatory Var #5    -0.9000   3.22e-16  -2.79e+15      0.000      -0.900      -0.900\n",
      "==============================================================================\n",
      "Omnibus:                        3.801   Durbin-Watson:                   0.648\n",
      "Prob(Omnibus):                  0.149   Jarque-Bera (JB):                4.066\n",
      "Skew:                          -0.114   Prob(JB):                        0.131\n",
      "Kurtosis:                       3.424   Cond. No.                         738.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(gls_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared and adjusted R-squared: 1.000 meaning that the independent variables explain all of the variation in the dependent variable\n",
    "\n",
    "F-Statistic: 2.671e+31 is a very high value meaning the model is statistically significant\n",
    "\n",
    "Prob(F-statistic): 0 is a very low value meaning the overall model is statistically significant\n",
    "\n",
    "Coefficients (Constant): 32 meaning when all other values have a value of 0, the dependent variable would have a value of 32\n",
    "\n",
    "Coefficients (Explanatory Variables): All of the explanatory variables have unique coefficients that would affect the model in their own unique way\n",
    "\n",
    "t-statistic: tells us how significant each of the explanantory variables are, the farther from 0 the more significant. All of our values have very high or very low t-statistic values\n",
    "\n",
    "p-value: tells us the probaility that coeficients are not significantly different from 0, we have only kept the variables that have had a p-value less than 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tSplit the dataset into two as the training and test sets (test size = 0.5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tRun the Lasso model with alpha=1 and estimate the coefficients using the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.26972628,  1.68394638,  2.02626245,  2.08756512, -0.91746375,\n",
       "       -0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.01314162,  0.        , -0.        ,  0.        , -0.03617731])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lasso = lm.Lasso(alpha=1).fit(X_train,y_train)\n",
    "model_lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tThen, calculate the mean absolute percentage error using the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the test data to create predictions, then use the correct calculation to get the absolute percentage errors. Finally, take the mean of that to get the mean absolute percentage errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_percentage_errors = abs((y_test - predictions) / y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = absolute_percentage_errors.mean()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE): 4.432190198291583\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the built in function to calculate the mean absolute percentage error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE): 4.432190198291583\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "mape = mape*100\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\tFind an approximate value for alpha that minimizes the mean absolute percentage error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "mape = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.001 - Mean Absolute Percentage Error: 0.0044128318074118334\n",
      "Alpha: 0.01 - Mean Absolute Percentage Error: 0.04429881163345532\n",
      "Alpha: 0.1 - Mean Absolute Percentage Error: 0.4432318654957986\n",
      "Alpha: 1 - Mean Absolute Percentage Error: 4.432190198291583\n",
      "Alpha: 10 - Mean Absolute Percentage Error: 8.587094351590437\n",
      "Alpha: 100 - Mean Absolute Percentage Error: 44.28770209373842\n"
     ]
    }
   ],
   "source": [
    "for i in alphas:\n",
    "    model_lasso = Lasso(alpha=i)\n",
    "    model_lasso.fit(X_train, y_train)\n",
    "\n",
    "    lasso_pred = model_lasso.predict(X_test)\n",
    "\n",
    "    mean_absolute_percent = (mean_absolute_percentage_error(y_test, lasso_pred)) * 100\n",
    "    mape.append(mean_absolute_percent)\n",
    "\n",
    "    print(f\"Alpha: {i} - Mean Absolute Percentage Error: {mean_absolute_percent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After testing all of the alpha values, 0.001 yields the lowest mean absolute percentage error value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tUse the demand data given in the table and develop an appropriate forecasting model (i.e., the tailored regularization discussed in the class—see your slides for more info) that exploits the available information given in the table as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe for the given demand data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'Month':     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25],\n",
    "                    'Demand':     [100, 112, 107, 103, 91, 85, 84, 85, 79, 81, 134, 86, 99, 89, 111, 114, 118, 163, 193, 143, 144, 202, 158, 160, 144],\n",
    "                    'Adv_Demand': [71, 30, 75, 64, 41, 51, 42, 51, 57, 49, 134, 52, 99, 56, 81, 79, 73, 163, 193, 99, 91, 202, 105, 101, 96]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set y to the target variable of Demand\n",
    "\n",
    "Set X to the explanantory variables of Month and Advanced Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Month', 'Adv_Demand']]\n",
    "y = data['Demand']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets\n",
    "\n",
    "We used the same test size as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin hyper parameter tuning by testing alpha values for both models. We will test alpha values of 0.001, 0.01, 0.1, 1, and 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={'alpha': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "lasso_param_grid = {'alpha': alphas}\n",
    "ridge_param_grid = {'alpha': alphas}\n",
    "\n",
    "lasso_grid = GridSearchCV(Lasso(), lasso_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_grid = GridSearchCV(Ridge(), ridge_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "ridge_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the best parameters for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha_lasso = lasso_grid.best_params_['alpha']\n",
    "best_alpha_ridge = ridge_grid.best_params_['alpha']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the models based on the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=100)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model = Lasso(alpha=best_alpha_lasso)\n",
    "ridge_model = Ridge(alpha=best_alpha_ridge)\n",
    "\n",
    "lasso_model.fit(X_train, y_train)\n",
    "ridge_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the models by getting the predictions and then calculating the root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso RMSE: 17.31937837652882\n",
      "Ridge RMSE: 17.295623361752114\n"
     ]
    }
   ],
   "source": [
    "lasso_predictions = lasso_model.predict(X_test)\n",
    "ridge_predictions = ridge_model.predict(X_test)\n",
    "\n",
    "lasso_rmse = sqrt(mean_squared_error(y_test, lasso_predictions))\n",
    "ridge_rmse = sqrt(mean_squared_error(y_test, ridge_predictions))\n",
    "\n",
    "print(f'Lasso RMSE: {lasso_rmse}')\n",
    "print(f'Ridge RMSE: {ridge_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tInterpret your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE value tells us that the better of the two models is the Ridge model as its RMSE value is 17.30 in comparison to that of the ridge model which has a RMSE value of 17.32\n",
    "\n",
    "Both models do not have the best RMSE value as it is telling us that it can predict demand based on advanced demand within 17 of the actual demand. When dealing with demand values between 100 and 200 this is not very accurate. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
