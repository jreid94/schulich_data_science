{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sl\n",
    "import matplotlib as mp\n",
    "import scipy as cp\n",
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
    "from sklearn.metrics import f1_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from math import sqrt\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.linalg import toeplitz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tDownload the “dataset_lm.csv” file from Canvas and upload it to Jupyter Notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\johns\\OneDrive\\Desktop\\MBAN Semester 2\\Predictive Analytics\\Assignment 1\\dataset_lm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a quick overview of the data through the use of the head and info function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependent Var</th>\n",
       "      <th>Explanatory Var #1</th>\n",
       "      <th>Explanatory Var #2</th>\n",
       "      <th>Explanatory Var #3</th>\n",
       "      <th>Explanatory Var #4</th>\n",
       "      <th>Explanatory Var #5</th>\n",
       "      <th>Explanatory Var #6</th>\n",
       "      <th>Explanatory Var #7</th>\n",
       "      <th>Explanatory Var #8</th>\n",
       "      <th>Explanatory Var #9</th>\n",
       "      <th>Explanatory Var #10</th>\n",
       "      <th>Explanatory Var #11</th>\n",
       "      <th>Explanatory Var #12</th>\n",
       "      <th>Explanatory Var #13</th>\n",
       "      <th>Explanatory Var #14</th>\n",
       "      <th>Explanatory Var #15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.293458</td>\n",
       "      <td>13.698667</td>\n",
       "      <td>50.639873</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.568035</td>\n",
       "      <td>45.121911</td>\n",
       "      <td>11.412501</td>\n",
       "      <td>56.410757</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.281132</td>\n",
       "      <td>38.996909</td>\n",
       "      <td>-3.010548</td>\n",
       "      <td>49.195073</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.153143</td>\n",
       "      <td>46.919314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.473431</td>\n",
       "      <td>2.714725</td>\n",
       "      <td>65.845845</td>\n",
       "      <td>1</td>\n",
       "      <td>-25.105932</td>\n",
       "      <td>47.190213</td>\n",
       "      <td>10.080280</td>\n",
       "      <td>65.383107</td>\n",
       "      <td>3</td>\n",
       "      <td>-36.763585</td>\n",
       "      <td>51.654939</td>\n",
       "      <td>4.991111</td>\n",
       "      <td>45.591729</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.474403</td>\n",
       "      <td>53.383508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.195330</td>\n",
       "      <td>11.618072</td>\n",
       "      <td>65.072497</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.897464</td>\n",
       "      <td>52.163036</td>\n",
       "      <td>11.057301</td>\n",
       "      <td>82.812717</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.733547</td>\n",
       "      <td>48.913837</td>\n",
       "      <td>-2.457696</td>\n",
       "      <td>56.608806</td>\n",
       "      <td>0</td>\n",
       "      <td>-27.903299</td>\n",
       "      <td>48.515026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.074583</td>\n",
       "      <td>0.818623</td>\n",
       "      <td>45.408996</td>\n",
       "      <td>1</td>\n",
       "      <td>-18.316132</td>\n",
       "      <td>54.356714</td>\n",
       "      <td>5.029029</td>\n",
       "      <td>48.812471</td>\n",
       "      <td>1</td>\n",
       "      <td>-12.825591</td>\n",
       "      <td>45.851732</td>\n",
       "      <td>14.974177</td>\n",
       "      <td>47.362594</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.064411</td>\n",
       "      <td>55.266254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86.035569</td>\n",
       "      <td>9.077544</td>\n",
       "      <td>73.548021</td>\n",
       "      <td>0</td>\n",
       "      <td>-19.204165</td>\n",
       "      <td>47.186807</td>\n",
       "      <td>12.128134</td>\n",
       "      <td>62.520911</td>\n",
       "      <td>2</td>\n",
       "      <td>-13.804860</td>\n",
       "      <td>47.765904</td>\n",
       "      <td>9.593982</td>\n",
       "      <td>53.700562</td>\n",
       "      <td>0</td>\n",
       "      <td>-17.546302</td>\n",
       "      <td>48.150543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dependent Var  Explanatory Var #1  Explanatory Var #2  Explanatory Var #3  \\\n",
       "0      56.293458           13.698667           50.639873                   0   \n",
       "1      58.473431            2.714725           65.845845                   1   \n",
       "2      94.195330           11.618072           65.072497                   0   \n",
       "3      29.074583            0.818623           45.408996                   1   \n",
       "4      86.035569            9.077544           73.548021                   0   \n",
       "\n",
       "   Explanatory Var #4  Explanatory Var #5  Explanatory Var #6  \\\n",
       "0          -18.568035           45.121911           11.412501   \n",
       "1          -25.105932           47.190213           10.080280   \n",
       "2           -7.897464           52.163036           11.057301   \n",
       "3          -18.316132           54.356714            5.029029   \n",
       "4          -19.204165           47.186807           12.128134   \n",
       "\n",
       "   Explanatory Var #7  Explanatory Var #8  Explanatory Var #9  \\\n",
       "0           56.410757                   2          -12.281132   \n",
       "1           65.383107                   3          -36.763585   \n",
       "2           82.812717                   0          -15.733547   \n",
       "3           48.812471                   1          -12.825591   \n",
       "4           62.520911                   2          -13.804860   \n",
       "\n",
       "   Explanatory Var #10  Explanatory Var #11  Explanatory Var #12  \\\n",
       "0            38.996909            -3.010548            49.195073   \n",
       "1            51.654939             4.991111            45.591729   \n",
       "2            48.913837            -2.457696            56.608806   \n",
       "3            45.851732            14.974177            47.362594   \n",
       "4            47.765904             9.593982            53.700562   \n",
       "\n",
       "   Explanatory Var #13  Explanatory Var #14  Explanatory Var #15  \n",
       "0                    0           -21.153143            46.919314  \n",
       "1                    0            -6.474403            53.383508  \n",
       "2                    0           -27.903299            48.515026  \n",
       "3                    1           -10.064411            55.266254  \n",
       "4                    0           -17.546302            48.150543  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422 entries, 0 to 421\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Dependent Var        422 non-null    float64\n",
      " 1   Explanatory Var #1   422 non-null    float64\n",
      " 2   Explanatory Var #2   422 non-null    float64\n",
      " 3   Explanatory Var #3   422 non-null    int64  \n",
      " 4   Explanatory Var #4   422 non-null    float64\n",
      " 5   Explanatory Var #5   422 non-null    float64\n",
      " 6   Explanatory Var #6   422 non-null    float64\n",
      " 7   Explanatory Var #7   422 non-null    float64\n",
      " 8   Explanatory Var #8   422 non-null    int64  \n",
      " 9   Explanatory Var #9   422 non-null    float64\n",
      " 10  Explanatory Var #10  422 non-null    float64\n",
      " 11  Explanatory Var #11  422 non-null    float64\n",
      " 12  Explanatory Var #12  422 non-null    float64\n",
      " 13  Explanatory Var #13  422 non-null    int64  \n",
      " 14  Explanatory Var #14  422 non-null    float64\n",
      " 15  Explanatory Var #15  422 non-null    float64\n",
      "dtypes: float64(13), int64(3)\n",
      "memory usage: 52.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tRun the OLS model by using the dependent and explanatory variables in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set y to the target variable Dependent Var\n",
    "\n",
    "Set X all of the explanatory variables by setting it to the entire dataset except the Dependent Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Dependent Var']\n",
    "X = df.drop('Dependent Var', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we created a regular model using the X and y created above. However, in the notes the model says that it would center if a constant was added.\n",
    "\n",
    "Next, we added a constant to the X value then created the updated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg = sm.OLS(y,X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_updated = sm.add_constant(X)\n",
    "model_updated = sm.OLS(y,x_updated).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tShow your summary table in Python and interpret your results in the summary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Dependent Var</td>  <th>  R-squared (uncentered):</th>      <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>4.509e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Oct 2023</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:14:52</td>     <th>  Log-Likelihood:    </th>          <td> -841.76</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   422</td>      <th>  AIC:               </th>          <td>   1714.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   407</td>      <th>  BIC:               </th>          <td>   1774.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #1</th>  <td>    1.3078</td> <td>    0.013</td> <td>  102.159</td> <td> 0.000</td> <td>    1.283</td> <td>    1.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #2</th>  <td>    1.7667</td> <td>    0.009</td> <td>  203.101</td> <td> 0.000</td> <td>    1.750</td> <td>    1.784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #3</th>  <td>    6.6083</td> <td>    0.177</td> <td>   37.232</td> <td> 0.000</td> <td>    6.259</td> <td>    6.957</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #4</th>  <td>    2.0725</td> <td>    0.011</td> <td>  189.896</td> <td> 0.000</td> <td>    2.051</td> <td>    2.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #5</th>  <td>   -0.7776</td> <td>    0.011</td> <td>  -68.372</td> <td> 0.000</td> <td>   -0.800</td> <td>   -0.755</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #6</th>  <td>    0.0124</td> <td>    0.008</td> <td>    1.595</td> <td> 0.111</td> <td>   -0.003</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #7</th>  <td>    0.0286</td> <td>    0.006</td> <td>    4.890</td> <td> 0.000</td> <td>    0.017</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #8</th>  <td>    0.3510</td> <td>    0.080</td> <td>    4.398</td> <td> 0.000</td> <td>    0.194</td> <td>    0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #9</th>  <td>   -0.0293</td> <td>    0.010</td> <td>   -2.838</td> <td> 0.005</td> <td>   -0.050</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #10</th> <td>    0.1292</td> <td>    0.011</td> <td>   11.409</td> <td> 0.000</td> <td>    0.107</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #11</th> <td>    0.0145</td> <td>    0.013</td> <td>    1.152</td> <td> 0.250</td> <td>   -0.010</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #12</th> <td>    0.0752</td> <td>    0.009</td> <td>    8.698</td> <td> 0.000</td> <td>    0.058</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #13</th> <td>    0.7414</td> <td>    0.177</td> <td>    4.198</td> <td> 0.000</td> <td>    0.394</td> <td>    1.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #14</th> <td>   -0.0218</td> <td>    0.011</td> <td>   -1.974</td> <td> 0.049</td> <td>   -0.043</td> <td>-8.61e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #15</th> <td>    0.1212</td> <td>    0.012</td> <td>   10.324</td> <td> 0.000</td> <td>    0.098</td> <td>    0.144</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.087</td> <th>  Durbin-Watson:     </th> <td>   1.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.957</td> <th>  Jarque-Bera (JB):  </th> <td>   0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.004</td> <th>  Prob(JB):          </th> <td>   0.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.897</td> <th>  Cond. No.          </th> <td>    287.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       &  Dependent Var   & \\textbf{  R-squared (uncentered):}      &     0.999   \\\\\n",
       "\\textbf{Model:}               &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.999   \\\\\n",
       "\\textbf{Method:}              &  Least Squares   & \\textbf{  F-statistic:       }          & 4.509e+04   \\\\\n",
       "\\textbf{Date:}                & Tue, 24 Oct 2023 & \\textbf{  Prob (F-statistic):}          &     0.00    \\\\\n",
       "\\textbf{Time:}                &     10:14:52     & \\textbf{  Log-Likelihood:    }          &   -841.76   \\\\\n",
       "\\textbf{No. Observations:}    &         422      & \\textbf{  AIC:               }          &     1714.   \\\\\n",
       "\\textbf{Df Residuals:}        &         407      & \\textbf{  BIC:               }          &     1774.   \\\\\n",
       "\\textbf{Df Model:}            &          15      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}     &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Explanatory Var \\#1}  &       1.3078  &        0.013     &   102.159  &         0.000        &        1.283    &        1.333     \\\\\n",
       "\\textbf{Explanatory Var \\#2}  &       1.7667  &        0.009     &   203.101  &         0.000        &        1.750    &        1.784     \\\\\n",
       "\\textbf{Explanatory Var \\#3}  &       6.6083  &        0.177     &    37.232  &         0.000        &        6.259    &        6.957     \\\\\n",
       "\\textbf{Explanatory Var \\#4}  &       2.0725  &        0.011     &   189.896  &         0.000        &        2.051    &        2.094     \\\\\n",
       "\\textbf{Explanatory Var \\#5}  &      -0.7776  &        0.011     &   -68.372  &         0.000        &       -0.800    &       -0.755     \\\\\n",
       "\\textbf{Explanatory Var \\#6}  &       0.0124  &        0.008     &     1.595  &         0.111        &       -0.003    &        0.028     \\\\\n",
       "\\textbf{Explanatory Var \\#7}  &       0.0286  &        0.006     &     4.890  &         0.000        &        0.017    &        0.040     \\\\\n",
       "\\textbf{Explanatory Var \\#8}  &       0.3510  &        0.080     &     4.398  &         0.000        &        0.194    &        0.508     \\\\\n",
       "\\textbf{Explanatory Var \\#9}  &      -0.0293  &        0.010     &    -2.838  &         0.005        &       -0.050    &       -0.009     \\\\\n",
       "\\textbf{Explanatory Var \\#10} &       0.1292  &        0.011     &    11.409  &         0.000        &        0.107    &        0.152     \\\\\n",
       "\\textbf{Explanatory Var \\#11} &       0.0145  &        0.013     &     1.152  &         0.250        &       -0.010    &        0.039     \\\\\n",
       "\\textbf{Explanatory Var \\#12} &       0.0752  &        0.009     &     8.698  &         0.000        &        0.058    &        0.092     \\\\\n",
       "\\textbf{Explanatory Var \\#13} &       0.7414  &        0.177     &     4.198  &         0.000        &        0.394    &        1.089     \\\\\n",
       "\\textbf{Explanatory Var \\#14} &      -0.0218  &        0.011     &    -1.974  &         0.049        &       -0.043    &    -8.61e-05     \\\\\n",
       "\\textbf{Explanatory Var \\#15} &       0.1212  &        0.012     &    10.324  &         0.000        &        0.098    &        0.144     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.087 & \\textbf{  Durbin-Watson:     } &    1.875  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.957 & \\textbf{  Jarque-Bera (JB):  } &    0.188  \\\\\n",
       "\\textbf{Skew:}          & -0.004 & \\textbf{  Prob(JB):          } &    0.910  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.897 & \\textbf{  Cond. No.          } &     287.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:          Dependent Var   R-squared (uncentered):                   0.999\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.999\n",
       "Method:                 Least Squares   F-statistic:                          4.509e+04\n",
       "Date:                Tue, 24 Oct 2023   Prob (F-statistic):                        0.00\n",
       "Time:                        10:14:52   Log-Likelihood:                         -841.76\n",
       "No. Observations:                 422   AIC:                                      1714.\n",
       "Df Residuals:                     407   BIC:                                      1774.\n",
       "Df Model:                          15                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "Explanatory Var #1      1.3078      0.013    102.159      0.000       1.283       1.333\n",
       "Explanatory Var #2      1.7667      0.009    203.101      0.000       1.750       1.784\n",
       "Explanatory Var #3      6.6083      0.177     37.232      0.000       6.259       6.957\n",
       "Explanatory Var #4      2.0725      0.011    189.896      0.000       2.051       2.094\n",
       "Explanatory Var #5     -0.7776      0.011    -68.372      0.000      -0.800      -0.755\n",
       "Explanatory Var #6      0.0124      0.008      1.595      0.111      -0.003       0.028\n",
       "Explanatory Var #7      0.0286      0.006      4.890      0.000       0.017       0.040\n",
       "Explanatory Var #8      0.3510      0.080      4.398      0.000       0.194       0.508\n",
       "Explanatory Var #9     -0.0293      0.010     -2.838      0.005      -0.050      -0.009\n",
       "Explanatory Var #10     0.1292      0.011     11.409      0.000       0.107       0.152\n",
       "Explanatory Var #11     0.0145      0.013      1.152      0.250      -0.010       0.039\n",
       "Explanatory Var #12     0.0752      0.009      8.698      0.000       0.058       0.092\n",
       "Explanatory Var #13     0.7414      0.177      4.198      0.000       0.394       1.089\n",
       "Explanatory Var #14    -0.0218      0.011     -1.974      0.049      -0.043   -8.61e-05\n",
       "Explanatory Var #15     0.1212      0.012     10.324      0.000       0.098       0.144\n",
       "==============================================================================\n",
       "Omnibus:                        0.087   Durbin-Watson:                   1.875\n",
       "Prob(Omnibus):                  0.957   Jarque-Bera (JB):                0.188\n",
       "Skew:                          -0.004   Prob(JB):                        0.910\n",
       "Kurtosis:                       2.897   Cond. No.                         287.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Dependent Var</td>  <th>  R-squared:         </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.488e+30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Oct 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:14:52</td>     <th>  Log-Likelihood:    </th>  <td>  11995.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   422</td>      <th>  AIC:               </th> <td>-2.396e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   406</td>      <th>  BIC:               </th> <td>-2.389e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>   32.0000</td> <td> 9.77e-14</td> <td> 3.28e+14</td> <td> 0.000</td> <td>   32.000</td> <td>   32.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #1</th>  <td>    1.3000</td> <td> 7.89e-16</td> <td> 1.65e+15</td> <td> 0.000</td> <td>    1.300</td> <td>    1.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #2</th>  <td>    1.7000</td> <td> 5.73e-16</td> <td> 2.97e+15</td> <td> 0.000</td> <td>    1.700</td> <td>    1.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #3</th>  <td>    6.2000</td> <td>  1.1e-14</td> <td> 5.64e+14</td> <td> 0.000</td> <td>    6.200</td> <td>    6.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #4</th>  <td>    2.1000</td> <td> 6.77e-16</td> <td>  3.1e+15</td> <td> 0.000</td> <td>    2.100</td> <td>    2.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #5</th>  <td>   -0.9000</td> <td> 7.94e-16</td> <td>-1.13e+15</td> <td> 0.000</td> <td>   -0.900</td> <td>   -0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #6</th>  <td> 4.163e-16</td> <td> 4.79e-16</td> <td>    0.869</td> <td> 0.385</td> <td>-5.25e-16</td> <td> 1.36e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #7</th>  <td> 1.277e-15</td> <td>  3.7e-16</td> <td>    3.450</td> <td> 0.001</td> <td> 5.49e-16</td> <td>    2e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #8</th>  <td>-7.661e-15</td> <td> 5.03e-15</td> <td>   -1.523</td> <td> 0.128</td> <td>-1.75e-14</td> <td> 2.23e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #9</th>  <td>  7.72e-16</td> <td> 6.43e-16</td> <td>    1.201</td> <td> 0.231</td> <td>-4.92e-16</td> <td> 2.04e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #10</th> <td>-1.693e-15</td> <td> 8.01e-16</td> <td>   -2.113</td> <td> 0.035</td> <td>-3.27e-15</td> <td>-1.18e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #11</th> <td> 2.404e-15</td> <td> 7.75e-16</td> <td>    3.103</td> <td> 0.002</td> <td> 8.81e-16</td> <td> 3.93e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #12</th> <td>-1.429e-15</td> <td>  5.8e-16</td> <td>   -2.465</td> <td> 0.014</td> <td>-2.57e-15</td> <td> -2.9e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #13</th> <td>-1.155e-14</td> <td> 1.11e-14</td> <td>   -1.039</td> <td> 0.299</td> <td>-3.34e-14</td> <td> 1.03e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #14</th> <td>-2.998e-15</td> <td> 6.82e-16</td> <td>   -4.396</td> <td> 0.000</td> <td>-4.34e-15</td> <td>-1.66e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #15</th> <td>-3.664e-15</td> <td> 8.12e-16</td> <td>   -4.512</td> <td> 0.000</td> <td>-5.26e-15</td> <td>-2.07e-15</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.418</td> <th>  Durbin-Watson:     </th> <td>   0.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.811</td> <th>  Jarque-Bera (JB):  </th> <td>   0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.007</td> <th>  Prob(JB):          </th> <td>   0.887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.116</td> <th>  Cond. No.          </th> <td>2.55e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.55e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       &  Dependent Var   & \\textbf{  R-squared:         } &     1.000   \\\\\n",
       "\\textbf{Model:}               &       OLS        & \\textbf{  Adj. R-squared:    } &     1.000   \\\\\n",
       "\\textbf{Method:}              &  Least Squares   & \\textbf{  F-statistic:       } & 1.488e+30   \\\\\n",
       "\\textbf{Date:}                & Tue, 24 Oct 2023 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                &     10:14:52     & \\textbf{  Log-Likelihood:    } &    11995.   \\\\\n",
       "\\textbf{No. Observations:}    &         422      & \\textbf{  AIC:               } & -2.396e+04  \\\\\n",
       "\\textbf{Df Residuals:}        &         406      & \\textbf{  BIC:               } & -2.389e+04  \\\\\n",
       "\\textbf{Df Model:}            &          15      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}     &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                &      32.0000  &     9.77e-14     &  3.28e+14  &         0.000        &       32.000    &       32.000     \\\\\n",
       "\\textbf{Explanatory Var \\#1}  &       1.3000  &     7.89e-16     &  1.65e+15  &         0.000        &        1.300    &        1.300     \\\\\n",
       "\\textbf{Explanatory Var \\#2}  &       1.7000  &     5.73e-16     &  2.97e+15  &         0.000        &        1.700    &        1.700     \\\\\n",
       "\\textbf{Explanatory Var \\#3}  &       6.2000  &      1.1e-14     &  5.64e+14  &         0.000        &        6.200    &        6.200     \\\\\n",
       "\\textbf{Explanatory Var \\#4}  &       2.1000  &     6.77e-16     &   3.1e+15  &         0.000        &        2.100    &        2.100     \\\\\n",
       "\\textbf{Explanatory Var \\#5}  &      -0.9000  &     7.94e-16     & -1.13e+15  &         0.000        &       -0.900    &       -0.900     \\\\\n",
       "\\textbf{Explanatory Var \\#6}  &    4.163e-16  &     4.79e-16     &     0.869  &         0.385        &    -5.25e-16    &     1.36e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#7}  &    1.277e-15  &      3.7e-16     &     3.450  &         0.001        &     5.49e-16    &        2e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#8}  &   -7.661e-15  &     5.03e-15     &    -1.523  &         0.128        &    -1.75e-14    &     2.23e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#9}  &     7.72e-16  &     6.43e-16     &     1.201  &         0.231        &    -4.92e-16    &     2.04e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#10} &   -1.693e-15  &     8.01e-16     &    -2.113  &         0.035        &    -3.27e-15    &    -1.18e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#11} &    2.404e-15  &     7.75e-16     &     3.103  &         0.002        &     8.81e-16    &     3.93e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#12} &   -1.429e-15  &      5.8e-16     &    -2.465  &         0.014        &    -2.57e-15    &     -2.9e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#13} &   -1.155e-14  &     1.11e-14     &    -1.039  &         0.299        &    -3.34e-14    &     1.03e-14     \\\\\n",
       "\\textbf{Explanatory Var \\#14} &   -2.998e-15  &     6.82e-16     &    -4.396  &         0.000        &    -4.34e-15    &    -1.66e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#15} &   -3.664e-15  &     8.12e-16     &    -4.512  &         0.000        &    -5.26e-15    &    -2.07e-15     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.418 & \\textbf{  Durbin-Watson:     } &    0.650  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.811 & \\textbf{  Jarque-Bera (JB):  } &    0.241  \\\\\n",
       "\\textbf{Skew:}          &  0.007 & \\textbf{  Prob(JB):          } &    0.887  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.116 & \\textbf{  Cond. No.          } & 2.55e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.55e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          Dependent Var   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 1.488e+30\n",
       "Date:                Tue, 24 Oct 2023   Prob (F-statistic):               0.00\n",
       "Time:                        10:14:52   Log-Likelihood:                 11995.\n",
       "No. Observations:                 422   AIC:                        -2.396e+04\n",
       "Df Residuals:                     406   BIC:                        -2.389e+04\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                  32.0000   9.77e-14   3.28e+14      0.000      32.000      32.000\n",
       "Explanatory Var #1      1.3000   7.89e-16   1.65e+15      0.000       1.300       1.300\n",
       "Explanatory Var #2      1.7000   5.73e-16   2.97e+15      0.000       1.700       1.700\n",
       "Explanatory Var #3      6.2000    1.1e-14   5.64e+14      0.000       6.200       6.200\n",
       "Explanatory Var #4      2.1000   6.77e-16    3.1e+15      0.000       2.100       2.100\n",
       "Explanatory Var #5     -0.9000   7.94e-16  -1.13e+15      0.000      -0.900      -0.900\n",
       "Explanatory Var #6   4.163e-16   4.79e-16      0.869      0.385   -5.25e-16    1.36e-15\n",
       "Explanatory Var #7   1.277e-15    3.7e-16      3.450      0.001    5.49e-16       2e-15\n",
       "Explanatory Var #8  -7.661e-15   5.03e-15     -1.523      0.128   -1.75e-14    2.23e-15\n",
       "Explanatory Var #9    7.72e-16   6.43e-16      1.201      0.231   -4.92e-16    2.04e-15\n",
       "Explanatory Var #10 -1.693e-15   8.01e-16     -2.113      0.035   -3.27e-15   -1.18e-16\n",
       "Explanatory Var #11  2.404e-15   7.75e-16      3.103      0.002    8.81e-16    3.93e-15\n",
       "Explanatory Var #12 -1.429e-15    5.8e-16     -2.465      0.014   -2.57e-15    -2.9e-16\n",
       "Explanatory Var #13 -1.155e-14   1.11e-14     -1.039      0.299   -3.34e-14    1.03e-14\n",
       "Explanatory Var #14 -2.998e-15   6.82e-16     -4.396      0.000   -4.34e-15   -1.66e-15\n",
       "Explanatory Var #15 -3.664e-15   8.12e-16     -4.512      0.000   -5.26e-15   -2.07e-15\n",
       "==============================================================================\n",
       "Omnibus:                        0.418   Durbin-Watson:                   0.650\n",
       "Prob(Omnibus):                  0.811   Jarque-Bera (JB):                0.241\n",
       "Skew:                           0.007   Prob(JB):                        0.887\n",
       "Kurtosis:                       3.116   Cond. No.                     2.55e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.55e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_updated.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets remove values that have a p-value greater than 0.05 as this tells us these values are not significantly different from 0\n",
    "\n",
    "I kept removing variables until I was left with no variables with a p-value greater than 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal 1\n",
    "x_updated = x_updated.drop(\"Explanatory Var #6\", axis = 1)\n",
    "x_updated = x_updated.drop(\"Explanatory Var #8\", axis = 1)\n",
    "x_updated = x_updated.drop(\"Explanatory Var #9\", axis = 1)\n",
    "x_updated = x_updated.drop(\"Explanatory Var #13\", axis = 1)\n",
    "\n",
    "# Removal 2\n",
    "x_updated = x_updated.drop(\"Explanatory Var #11\", axis = 1)\n",
    "x_updated = x_updated.drop(\"Explanatory Var #12\", axis = 1)\n",
    "x_updated = x_updated.drop(\"Explanatory Var #15\", axis = 1)\n",
    "\n",
    "# Removal 3\n",
    "x_updated = x_updated.drop(\"Explanatory Var #7\", axis = 1)\n",
    "x_updated = x_updated.drop(\"Explanatory Var #10\", axis = 1)\n",
    "x_updated = x_updated.drop(\"Explanatory Var #14\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Dependent Var</td>  <th>  R-squared:         </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>3.870e+31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Oct 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:14:53</td>     <th>  Log-Likelihood:    </th>  <td>  12446.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   422</td>      <th>  AIC:               </th> <td>-2.488e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   416</td>      <th>  BIC:               </th> <td>-2.486e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>   32.0000</td> <td>  1.8e-14</td> <td> 1.78e+15</td> <td> 0.000</td> <td>   32.000</td> <td>   32.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #1</th> <td>    1.3000</td> <td> 2.65e-16</td> <td>  4.9e+15</td> <td> 0.000</td> <td>    1.300</td> <td>    1.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #2</th> <td>    1.7000</td> <td> 1.93e-16</td> <td>  8.8e+15</td> <td> 0.000</td> <td>    1.700</td> <td>    1.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #3</th> <td>    6.2000</td> <td> 3.69e-15</td> <td> 1.68e+15</td> <td> 0.000</td> <td>    6.200</td> <td>    6.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #4</th> <td>    2.1000</td> <td> 2.29e-16</td> <td> 9.18e+15</td> <td> 0.000</td> <td>    2.100</td> <td>    2.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #5</th> <td>   -0.9000</td> <td> 2.65e-16</td> <td>-3.39e+15</td> <td> 0.000</td> <td>   -0.900</td> <td>   -0.900</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.824</td> <th>  Durbin-Watson:     </th> <td>   1.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.148</td> <th>  Jarque-Bera (JB):  </th> <td>   2.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.017</td> <th>  Prob(JB):          </th> <td>   0.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.602</td> <th>  Cond. No.          </th> <td>    785.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}      &  Dependent Var   & \\textbf{  R-squared:         } &     1.000   \\\\\n",
       "\\textbf{Model:}              &       OLS        & \\textbf{  Adj. R-squared:    } &     1.000   \\\\\n",
       "\\textbf{Method:}             &  Least Squares   & \\textbf{  F-statistic:       } & 3.870e+31   \\\\\n",
       "\\textbf{Date:}               & Tue, 24 Oct 2023 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}               &     10:14:53     & \\textbf{  Log-Likelihood:    } &    12446.   \\\\\n",
       "\\textbf{No. Observations:}   &         422      & \\textbf{  AIC:               } & -2.488e+04  \\\\\n",
       "\\textbf{Df Residuals:}       &         416      & \\textbf{  BIC:               } & -2.486e+04  \\\\\n",
       "\\textbf{Df Model:}           &           5      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}    &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                             & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}               &      32.0000  &      1.8e-14     &  1.78e+15  &         0.000        &       32.000    &       32.000     \\\\\n",
       "\\textbf{Explanatory Var \\#1} &       1.3000  &     2.65e-16     &   4.9e+15  &         0.000        &        1.300    &        1.300     \\\\\n",
       "\\textbf{Explanatory Var \\#2} &       1.7000  &     1.93e-16     &   8.8e+15  &         0.000        &        1.700    &        1.700     \\\\\n",
       "\\textbf{Explanatory Var \\#3} &       6.2000  &     3.69e-15     &  1.68e+15  &         0.000        &        6.200    &        6.200     \\\\\n",
       "\\textbf{Explanatory Var \\#4} &       2.1000  &     2.29e-16     &  9.18e+15  &         0.000        &        2.100    &        2.100     \\\\\n",
       "\\textbf{Explanatory Var \\#5} &      -0.9000  &     2.65e-16     & -3.39e+15  &         0.000        &       -0.900    &       -0.900     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  3.824 & \\textbf{  Durbin-Watson:     } &    1.371  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.148 & \\textbf{  Jarque-Bera (JB):  } &    2.806  \\\\\n",
       "\\textbf{Skew:}          & -0.017 & \\textbf{  Prob(JB):          } &    0.246  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.602 & \\textbf{  Cond. No.          } &     785.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          Dependent Var   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 3.870e+31\n",
       "Date:                Tue, 24 Oct 2023   Prob (F-statistic):               0.00\n",
       "Time:                        10:14:53   Log-Likelihood:                 12446.\n",
       "No. Observations:                 422   AIC:                        -2.488e+04\n",
       "Df Residuals:                     416   BIC:                        -2.486e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                 32.0000    1.8e-14   1.78e+15      0.000      32.000      32.000\n",
       "Explanatory Var #1     1.3000   2.65e-16    4.9e+15      0.000       1.300       1.300\n",
       "Explanatory Var #2     1.7000   1.93e-16    8.8e+15      0.000       1.700       1.700\n",
       "Explanatory Var #3     6.2000   3.69e-15   1.68e+15      0.000       6.200       6.200\n",
       "Explanatory Var #4     2.1000   2.29e-16   9.18e+15      0.000       2.100       2.100\n",
       "Explanatory Var #5    -0.9000   2.65e-16  -3.39e+15      0.000      -0.900      -0.900\n",
       "==============================================================================\n",
       "Omnibus:                        3.824   Durbin-Watson:                   1.371\n",
       "Prob(Omnibus):                  0.148   Jarque-Bera (JB):                2.806\n",
       "Skew:                          -0.017   Prob(JB):                        0.246\n",
       "Kurtosis:                       2.602   Cond. No.                         785.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_updated = sm.OLS(y,x_updated).fit()\n",
    "model_updated.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared and adjusted R-squared: 1.000 meaning that the independent variables explain all of the variation in the dependent variable\n",
    "\n",
    "F-Statistic: 3.870e+31 is a very high value meaning the model is statistically significant\n",
    "\n",
    "Prob(F-statistic): 0 is a very low value meaning the overall model is statistically significant\n",
    "\n",
    "Coefficients (Constant): 32 meaning when all other values have a value of 0, the dependent variable would have a value of 32\n",
    "\n",
    "Coefficients (Explanatory Variables): All of the explanatory variables have unique coefficients that would affect the model in their own unique way\n",
    "\n",
    "t-statistic: tells us how significant each of the explanantory variables are, the farther from 0 the more significant\n",
    "\n",
    "p-value: tells us the probaility that coeficients are not significantly different from 0, we have only kept the variables that have had a p-value less than 0.05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tUse error values from the OLS model to calculate their standard deviation and autocorrelation values for the first three lags. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the error values we will first get the predicted values\n",
    "\n",
    "Then subtract the predicted values from the actual values to get the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      4.825713\n",
       "1     -0.197803\n",
       "2      0.975013\n",
       "3      1.853953\n",
       "4      1.110946\n",
       "         ...   \n",
       "417   -3.236116\n",
       "418   -0.454778\n",
       "419    2.851672\n",
       "420   -2.647010\n",
       "421    1.035218\n",
       "Length: 422, dtype: float64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_vals = model_reg.predict(X)\n",
    "errors = y - pred_vals\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then used the standard deviation function (std) to calculate the standard deviation of the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7757282184664"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_dev = np.std(errors)\n",
    "st_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9338889427200325, 0.8568714054990086, 0.8841512562268686]\n"
     ]
    }
   ],
   "source": [
    "lags = 3\n",
    "i = 0\n",
    "\n",
    "autocorrelation = [np.corrcoef(df[i:], df[:-i])[0, 1] for i in range(1, lags + 1)]\n",
    "print(autocorrelation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tThen, run the GLS model accordingly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get from lesson 3\n",
    "\n",
    "use cov_matrix function (1, cov1, cov2, cov3, np.zeros(418))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.15321071, 2.94474861, 2.70189609, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [2.94474861, 3.15321071, 2.94474861, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [2.70189609, 2.94474861, 3.15321071, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 3.15321071, 2.94474861,\n",
       "        2.70189609],\n",
       "       [0.        , 0.        , 0.        , ..., 2.94474861, 3.15321071,\n",
       "        2.94474861],\n",
       "       [0.        , 0.        , 0.        , ..., 2.70189609, 2.94474861,\n",
       "        3.15321071]])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_matrix = st_dev**2*toeplitz(np.append([1, autocorrelation[0], autocorrelation[1], autocorrelation[2]], np.zeros(418)))\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "5-th leading minor of the array is not positive definite",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mjreid94\\schulich_data_science\\Predictive Analytics\\Assignments\\A1.2.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell://github/jreid94/schulich_data_science/Predictive%20Analytics/Assignments/A1.2.ipynb#Y131sdnNjb2RlLXZmcw%3D%3D?line=0'>1</a>\u001b[0m sm\u001b[39m.\u001b[39;49mGLS(y,x_updated,cov_matrix)\u001b[39m.\u001b[39mfit()\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:536\u001b[0m, in \u001b[0;36mGLS.__init__\u001b[1;34m(self, endog, exog, sigma, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_kwargs(kwargs)\n\u001b[0;32m    534\u001b[0m \u001b[39m# TODO: add options igls, for iterative fgls if sigma is None\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[39m# TODO: default if sigma is none should be two-step GLS\u001b[39;00m\n\u001b[1;32m--> 536\u001b[0m sigma, cholsigmainv \u001b[39m=\u001b[39m _get_sigma(sigma, \u001b[39mlen\u001b[39;49m(endog))\n\u001b[0;32m    538\u001b[0m \u001b[39msuper\u001b[39m(GLS, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(endog, exog, missing\u001b[39m=\u001b[39mmissing,\n\u001b[0;32m    539\u001b[0m                           hasconst\u001b[39m=\u001b[39mhasconst, sigma\u001b[39m=\u001b[39msigma,\n\u001b[0;32m    540\u001b[0m                           cholsigmainv\u001b[39m=\u001b[39mcholsigmainv, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    542\u001b[0m \u001b[39m# store attribute names for data arrays\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:185\u001b[0m, in \u001b[0;36m_get_sigma\u001b[1;34m(sigma, nobs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m sigma\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m (nobs, nobs):\n\u001b[0;32m    183\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSigma must be a scalar, 1d of length \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m or a 2d \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    184\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39marray of shape \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m x \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (nobs, nobs, nobs))\n\u001b[1;32m--> 185\u001b[0m cholsigmainv, info \u001b[39m=\u001b[39m dtrtri(cholesky(sigma, lower\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[0;32m    186\u001b[0m                             lower\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, overwrite_c\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    187\u001b[0m \u001b[39mif\u001b[39;00m info \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    188\u001b[0m     \u001b[39mraise\u001b[39;00m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mLinAlgError(\u001b[39m'\u001b[39m\u001b[39mCholesky decomposition of sigma \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    189\u001b[0m                                 \u001b[39m'\u001b[39m\u001b[39myields a singular matrix\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py:89\u001b[0m, in \u001b[0;36mcholesky\u001b[1;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcholesky\u001b[39m(a, lower\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, overwrite_a\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, check_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m     46\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39m    Compute the Cholesky decomposition of a matrix.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m \n\u001b[0;32m     88\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m     c, lower \u001b[39m=\u001b[39m _cholesky(a, lower\u001b[39m=\u001b[39;49mlower, overwrite_a\u001b[39m=\u001b[39;49moverwrite_a, clean\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     90\u001b[0m                          check_finite\u001b[39m=\u001b[39;49mcheck_finite)\n\u001b[0;32m     91\u001b[0m     \u001b[39mreturn\u001b[39;00m c\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py:37\u001b[0m, in \u001b[0;36m_cholesky\u001b[1;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[0;32m     35\u001b[0m c, info \u001b[39m=\u001b[39m potrf(a1, lower\u001b[39m=\u001b[39mlower, overwrite_a\u001b[39m=\u001b[39moverwrite_a, clean\u001b[39m=\u001b[39mclean)\n\u001b[0;32m     36\u001b[0m \u001b[39mif\u001b[39;00m info \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 37\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-th leading minor of the array is not positive \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mdefinite\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m info)\n\u001b[0;32m     39\u001b[0m \u001b[39mif\u001b[39;00m info \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     40\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mLAPACK reported an illegal value in \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m-th argument\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     41\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mon entry to \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPOTRF\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m-\u001b[39minfo))\n",
      "\u001b[1;31mLinAlgError\u001b[0m: 5-th leading minor of the array is not positive definite"
     ]
    }
   ],
   "source": [
    "sm.GLS(y,x_updated,cov_matrix).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gls_model = sm.GLS(y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\genmod\\cov_struct.py:796: FutureWarning: grid=True will become default in a future version\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "order = 1\n",
    "cov_structure = sm.cov_struct.Autoregressive(order)\n",
    "gls_model.cov_struct = cov_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gls_results = gls_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tShow your summary table in Python and interpret your results in the summary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 GLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:          Dependent Var   R-squared (uncentered):                   0.999\n",
      "Model:                            GLS   Adj. R-squared (uncentered):              0.999\n",
      "Method:                 Least Squares   F-statistic:                          4.509e+04\n",
      "Date:                Tue, 24 Oct 2023   Prob (F-statistic):                        0.00\n",
      "Time:                        09:14:23   Log-Likelihood:                         -841.76\n",
      "No. Observations:                 422   AIC:                                      1714.\n",
      "Df Residuals:                     407   BIC:                                      1774.\n",
      "Df Model:                          15                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Explanatory Var #1      1.3078      0.013    102.159      0.000       1.283       1.333\n",
      "Explanatory Var #2      1.7667      0.009    203.101      0.000       1.750       1.784\n",
      "Explanatory Var #3      6.6083      0.177     37.232      0.000       6.259       6.957\n",
      "Explanatory Var #4      2.0725      0.011    189.896      0.000       2.051       2.094\n",
      "Explanatory Var #5     -0.7776      0.011    -68.372      0.000      -0.800      -0.755\n",
      "Explanatory Var #6      0.0124      0.008      1.595      0.111      -0.003       0.028\n",
      "Explanatory Var #7      0.0286      0.006      4.890      0.000       0.017       0.040\n",
      "Explanatory Var #8      0.3510      0.080      4.398      0.000       0.194       0.508\n",
      "Explanatory Var #9     -0.0293      0.010     -2.838      0.005      -0.050      -0.009\n",
      "Explanatory Var #10     0.1292      0.011     11.409      0.000       0.107       0.152\n",
      "Explanatory Var #11     0.0145      0.013      1.152      0.250      -0.010       0.039\n",
      "Explanatory Var #12     0.0752      0.009      8.698      0.000       0.058       0.092\n",
      "Explanatory Var #13     0.7414      0.177      4.198      0.000       0.394       1.089\n",
      "Explanatory Var #14    -0.0218      0.011     -1.974      0.049      -0.043   -8.61e-05\n",
      "Explanatory Var #15     0.1212      0.012     10.324      0.000       0.098       0.144\n",
      "==============================================================================\n",
      "Omnibus:                        0.087   Durbin-Watson:                   1.875\n",
      "Prob(Omnibus):                  0.957   Jarque-Bera (JB):                0.188\n",
      "Skew:                          -0.004   Prob(JB):                        0.910\n",
      "Kurtosis:                       2.897   Cond. No.                         287.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(gls_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tSplit the dataset into two as the training and test sets (test size = 0.5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tRun the Lasso model with alpha=1 and estimate the coefficients using the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.26972628,  1.68394638,  2.02626245,  2.08756512, -0.91746375,\n",
       "       -0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.01314162,  0.        , -0.        ,  0.        , -0.03617731])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lasso = lm.Lasso(alpha=1).fit(X_train,y_train)\n",
    "model_lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tThen, calculate the mean absolute percentage error using the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the test data to create predictions, then use the correct calculation to get the absolute percentage errors. Finally, take the mean of that to get the mean absolute percentage errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_percentage_errors = abs((y_test - predictions) / y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = absolute_percentage_errors.mean()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE): 4.432190198291583\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the built in function to calculate the mean absolute percentage error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE): 4.432190198291583\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "mape = mape*100\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\tFind an approximate value for alpha that minimizes the mean absolute percentage error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE) for Alpha 0.01: 0.04429881163345532\n"
     ]
    }
   ],
   "source": [
    "model_lasso = lm.Lasso(alpha=0.01).fit(X_train,y_train)\n",
    "model_lasso.coef_\n",
    "\n",
    "predictions = model_lasso.predict(X_test)\n",
    "absolute_percentage_errors = abs((y_test - predictions) / y_test) * 100\n",
    "mape = absolute_percentage_errors.mean()    \n",
    "print(\"Mean Absolute Percentage Error (MAPE) for Alpha 0.01:\", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE) for Alpha 0.1: 0.44323186549579874\n"
     ]
    }
   ],
   "source": [
    "model_lasso = lm.Lasso(alpha=0.1).fit(X_train,y_train)\n",
    "model_lasso.coef_\n",
    "\n",
    "predictions = model_lasso.predict(X_test)\n",
    "absolute_percentage_errors = abs((y_test - predictions) / y_test) * 100\n",
    "mape = absolute_percentage_errors.mean()    \n",
    "print(\"Mean Absolute Percentage Error (MAPE) for Alpha 0.1:\", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE) for Alpha 10: 8.587094351590437\n"
     ]
    }
   ],
   "source": [
    "model_lasso = lm.Lasso(alpha=10).fit(X_train,y_train)\n",
    "model_lasso.coef_\n",
    "\n",
    "predictions = model_lasso.predict(X_test)\n",
    "absolute_percentage_errors = abs((y_test - predictions) / y_test) * 100\n",
    "mape = absolute_percentage_errors.mean()    \n",
    "print(\"Mean Absolute Percentage Error (MAPE) for Alpha 10:\", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE) for Alpha 100: 44.287702093738424\n"
     ]
    }
   ],
   "source": [
    "model_lasso = lm.Lasso(alpha=100).fit(X_train,y_train)\n",
    "model_lasso.coef_\n",
    "\n",
    "predictions = model_lasso.predict(X_test)\n",
    "absolute_percentage_errors = abs((y_test - predictions) / y_test) * 100\n",
    "mape = absolute_percentage_errors.mean()    \n",
    "print(\"Mean Absolute Percentage Error (MAPE) for Alpha 100:\", mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Percentage Error (MAPE) for Alpha 0.01: 0.04429881163345532\n",
    "\n",
    "Mean Absolute Percentage Error (MAPE) for Alpha 0.1: 0.44323186549579874\n",
    "\n",
    "Mean Absolute Percentage Error (MAPE) for Alpha 1: 4.432190198291583\n",
    "\n",
    "Mean Absolute Percentage Error (MAPE) for Alpha 10: 8.587094351590437\n",
    "\n",
    "Mean Absolute Percentage Error (MAPE) for Alpha 100: 44.287702093738424"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After testing all of the alpha values, 0.01 yields the lowest mean absolute percentage error value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tUse the demand data given in the table and develop an appropriate forecasting model (i.e., the tailored regularization discussed in the class—see your slides for more info) that exploits the available information given in the table as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe for the given demand data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'Month':     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25],\n",
    "                    'Demand':     [100, 112, 107, 103, 91, 85, 84, 85, 79, 81, 134, 86, 99, 89, 111, 114, 118, 163, 193, 143, 144, 202, 158, 160, 144],\n",
    "                    'Adv_Demand': [71, 30, 75, 64, 41, 51, 42, 51, 57, 49, 134, 52, 99, 56, 81, 79, 73, 163, 193, 99, 91, 202, 105, 101, 96]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set y to the target variable of Demand\n",
    "\n",
    "Set X to the explanantory variables of Month and Advanced Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Month', 'Adv_Demand']]\n",
    "y = data['Demand']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin hyper parameter tuning by testing alpha values for both models. We will test alpha values of 0.001, 0.01, 0.1, 1, and 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.001, 0.01, 0.1, 1, 10]\n",
    "lasso_param_grid = {'alpha': alphas}\n",
    "ridge_param_grid = {'alpha': alphas}\n",
    "\n",
    "lasso_grid = GridSearchCV(Lasso(), lasso_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_grid = GridSearchCV(Ridge(), ridge_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "ridge_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the best parameters for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha_lasso = lasso_grid.best_params_['alpha']\n",
    "best_alpha_ridge = ridge_grid.best_params_['alpha']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the models based on the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = Lasso(alpha=best_alpha_lasso)\n",
    "ridge_model = Ridge(alpha=best_alpha_ridge)\n",
    "\n",
    "lasso_model.fit(X_train, y_train)\n",
    "ridge_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the models by getting the predictions and then calculating the root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_predictions = lasso_model.predict(X_test)\n",
    "ridge_predictions = ridge_model.predict(X_test)\n",
    "\n",
    "lasso_rmse = sqrt(mean_squared_error(y_test, lasso_predictions))\n",
    "ridge_rmse = sqrt(mean_squared_error(y_test, ridge_predictions))\n",
    "\n",
    "print(f'Lasso RMSE: {lasso_rmse}')\n",
    "print(f'Ridge RMSE: {ridge_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tInterpret your results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
