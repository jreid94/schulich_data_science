{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 3: Image Classification"
      ],
      "metadata": {
        "id": "5Nxe4h1yv_Yz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### By: John Reid"
      ],
      "metadata": {
        "id": "3Xk8gC1qwCyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the required packages"
      ],
      "metadata": {
        "id": "qMJDMyoSv63O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.image import resize_with_crop_or_pad\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "uBiC4eJpoHX5"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Preprocessing"
      ],
      "metadata": {
        "id": "pTzJ0K36GXAg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the stanord dogs dataset using the tensorflow datasets. The data is then split into training and testing datasets."
      ],
      "metadata": {
        "id": "wnW3ITclwVBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    (train_data, test_data), info = tfds.load('stanford_dogs', split=['train', 'test'], with_info=True, as_supervised=True)\n",
        "    return train_data, test_data, info"
      ],
      "metadata": {
        "id": "rQRGOeaxfm9I"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we resize the image to the desired image size, this ensures there is a consistent size of 128x128.\n",
        "\n",
        "Next, we one hot encode the label and use a depth of 120."
      ],
      "metadata": {
        "id": "yyfq9otxww3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, image_size)\n",
        "    image = resize_with_crop_or_pad(image, 128, 128)\n",
        "    label = tf.one_hot(label, depth=120)\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "M05fDPDqR-2R"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This sets the deisred image size to 128x128 and the desired validation split which is 10%"
      ],
      "metadata": {
        "id": "G_ga0pAXxE2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (128, 128)\n",
        "validation_split = 0.1"
      ],
      "metadata": {
        "id": "t4Wtb9QJQH6z"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data, info = load_data()"
      ],
      "metadata": {
        "id": "RLImJiv-HFSr"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.map(preprocess)"
      ],
      "metadata": {
        "id": "940LsVsUgONW"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Model Building"
      ],
      "metadata": {
        "id": "fm5bf6xQGf8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are designing the convolutional neural network by defining the layers we want to use along with the number of neurons and other required information."
      ],
      "metadata": {
        "id": "aWES3e6TxVxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conv2D is the convolutional layers which extract features using 64, 128, and 256 filters which all have the size 3x3.\n",
        "\n",
        "MaxPooling2D is the pooling layer which reduces spatial dimensions.\n",
        "\n",
        "Dropout is the dropout layer which is applied to the fully connected layer in order to reduce overfitting.\n",
        "\n",
        "Dense is the fully connected layer and is using 1024 neurons and relu activiation."
      ],
      "metadata": {
        "id": "dhEcR8ycaI4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_model = models.Sequential()\n",
        "\n",
        "custom_model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "custom_model.add(layers.MaxPooling2D((2, 2)))\n",
        "custom_model.add(layers.BatchNormalization())\n",
        "\n",
        "custom_model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "custom_model.add(layers.MaxPooling2D((2, 2)))\n",
        "custom_model.add(layers.BatchNormalization())\n",
        "\n",
        "custom_model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "custom_model.add(layers.MaxPooling2D((2, 2)))\n",
        "custom_model.add(layers.BatchNormalization())\n",
        "\n",
        "custom_model.add(layers.Flatten())\n",
        "\n",
        "custom_model.add(layers.Dense(512, activation='relu'))\n",
        "custom_model.add(layers.Dropout(0.5))\n",
        "custom_model.add(layers.BatchNormalization())\n",
        "\n",
        "custom_model.add(layers.Dense(1024, activation='relu'))\n",
        "custom_model.add(layers.Dropout(0.5))\n",
        "custom_model.add(layers.BatchNormalization())\n",
        "\n",
        "custom_model.add(layers.Dense(info.features['label'].num_classes, activation='softmax'))\n",
        "\n",
        "custom_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQINhjLyI788",
        "outputId": "7fa78585-181f-4333-e936-52bd6690a238"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 126, 126, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPooli  (None, 63, 63, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_30 (Ba  (None, 63, 63, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 61, 61, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPooli  (None, 30, 30, 128)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_31 (Ba  (None, 30, 30, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 28, 28, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPooli  (None, 14, 14, 256)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_32 (Ba  (None, 14, 14, 256)       1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 50176)             0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 512)               25690624  \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_33 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1024)              525312    \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_34 (Ba  (None, 1024)              4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 120)               123000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26717688 (101.92 MB)\n",
            "Trainable params: 26713720 (101.90 MB)\n",
            "Non-trainable params: 3968 (15.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Model Training and Optimization"
      ],
      "metadata": {
        "id": "CfhjKr1QGl9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_model1 = custom_model\n",
        "custom_model2 = custom_model\n",
        "#custom_model3 = custom_model"
      ],
      "metadata": {
        "id": "gcx9_O9avpVK"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by retrieving the number of training samples from the information within the dataset.\n",
        "\n",
        "Then calculate the number of validation samples using the total training samples and the validation split specified above."
      ],
      "metadata": {
        "id": "Qpog1GKnx7Y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_train_samples = info.splits['train'].num_examples\n",
        "num_validation_samples = int(validation_split * total_train_samples)"
      ],
      "metadata": {
        "id": "d4348wPVgpkr"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are creating a validation dataset by taking the num_validation_samples from the training data then adjusting the training dataset by using the skip function to exclude the num_validation_samples from the training set"
      ],
      "metadata": {
        "id": "oHC_f6XjyKFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = train_data.take(num_validation_samples)\n",
        "train_data = train_data.skip(num_validation_samples)"
      ],
      "metadata": {
        "id": "T5rkfu4cx6by"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is to retrive the amount of images in the validation and training sets."
      ],
      "metadata": {
        "id": "r9uhO7WOym-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_val_images = tf.data.experimental.cardinality(val_data).numpy()\n",
        "num_train_images = tf.data.experimental.cardinality(train_data).numpy()\n",
        "\n",
        "print(f\"Number of images in val_data: {num_val_images}\")\n",
        "print(f\"Number of images in train_data: {num_train_images}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poiVo6q7iuUa",
        "outputId": "82fd18e0-308d-43ad-b834-517565792195"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in val_data: 1200\n",
            "Number of images in train_data: 10800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the bath size for both the training and validation set."
      ],
      "metadata": {
        "id": "_nhY9Nlpy46o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32"
      ],
      "metadata": {
        "id": "1qZOPj19y6PU"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch both sets with the specified batch_size."
      ],
      "metadata": {
        "id": "4UerQpdKzAmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.batch(batch_size)\n",
        "val_data = val_data.batch(batch_size)"
      ],
      "metadata": {
        "id": "PiSbnTrjgjd_"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculate the number of epoch steps there should be for both sets."
      ],
      "metadata": {
        "id": "fjuA7FERzISC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_steps_per_epoch = len(train_data)\n",
        "val_steps_per_epoch = len(val_data)"
      ],
      "metadata": {
        "id": "w6BgDEbbzH-t"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "monitors the val loss value to determine if there should be early stop.\n",
        "\n",
        "The patience of 6 tells us that without any improvement after the 6th epoch, the training will stop.\n",
        "\n",
        "Restore best weights makes sure model weights are restored to the best values after the training is complete."
      ],
      "metadata": {
        "id": "Wc6R4_DszYa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "r2DRrldwzAHa"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "saves the best model which is evaluated on the val_accuracy"
      ],
      "metadata": {
        "id": "dZzY0dCPzUbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)"
      ],
      "metadata": {
        "id": "Dd-LsPXkzS5K"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizer is set to adam as it works well for a large array of models and is a good place to start.\n",
        "\n",
        "The loss function is set to categorical_crossentropy as this is ideal for multi-class classification tasks like the Stanford dogs datset."
      ],
      "metadata": {
        "id": "AjdXk8R1zwCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Yl_m52ICg6wn"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = custom_model1.fit(\n",
        "    train_data,\n",
        "    steps_per_epoch=train_steps_per_epoch,\n",
        "    epochs=20,\n",
        "    validation_data=val_data,\n",
        "    validation_steps=val_steps_per_epoch,\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LHXC3VBgEBd",
        "outputId": "77f4837e-a015-4d2a-f1aa-6e367f0364cf"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "337/338 [============================>.] - ETA: 0s - loss: 5.3070 - accuracy: 0.0167"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r338/338 [==============================] - 44s 112ms/step - loss: 5.3063 - accuracy: 0.0168 - val_loss: 4.7313 - val_accuracy: 0.0375\n",
            "Epoch 2/20\n",
            "338/338 [==============================] - 21s 58ms/step - loss: 4.8537 - accuracy: 0.0316 - val_loss: 4.7029 - val_accuracy: 0.0325\n",
            "Epoch 3/20\n",
            "338/338 [==============================] - 29s 82ms/step - loss: 4.6111 - accuracy: 0.0458 - val_loss: 4.3189 - val_accuracy: 0.0592\n",
            "Epoch 4/20\n",
            "338/338 [==============================] - 28s 79ms/step - loss: 4.3732 - accuracy: 0.0592 - val_loss: 5.0183 - val_accuracy: 0.0342\n",
            "Epoch 5/20\n",
            "338/338 [==============================] - 22s 63ms/step - loss: 4.1540 - accuracy: 0.0819 - val_loss: 5.1605 - val_accuracy: 0.0325\n",
            "Epoch 6/20\n",
            "338/338 [==============================] - 29s 82ms/step - loss: 3.9323 - accuracy: 0.1037 - val_loss: 4.5355 - val_accuracy: 0.0617\n",
            "Epoch 7/20\n",
            "338/338 [==============================] - 29s 82ms/step - loss: 3.6944 - accuracy: 0.1377 - val_loss: 4.1588 - val_accuracy: 0.0992\n",
            "Epoch 8/20\n",
            "338/338 [==============================] - 23s 64ms/step - loss: 3.4197 - accuracy: 0.1882 - val_loss: 4.2328 - val_accuracy: 0.0792\n",
            "Epoch 9/20\n",
            "338/338 [==============================] - 21s 59ms/step - loss: 3.1510 - accuracy: 0.2377 - val_loss: 4.0985 - val_accuracy: 0.0908\n",
            "Epoch 10/20\n",
            "338/338 [==============================] - 23s 66ms/step - loss: 2.8668 - accuracy: 0.2945 - val_loss: 4.3185 - val_accuracy: 0.0925\n",
            "Epoch 11/20\n",
            "338/338 [==============================] - 23s 64ms/step - loss: 2.4332 - accuracy: 0.3808 - val_loss: 4.5206 - val_accuracy: 0.0833\n",
            "Epoch 12/20\n",
            "338/338 [==============================] - 21s 59ms/step - loss: 2.3248 - accuracy: 0.3954 - val_loss: 4.6579 - val_accuracy: 0.0825\n",
            "Epoch 13/20\n",
            "338/338 [==============================] - 23s 64ms/step - loss: 2.4317 - accuracy: 0.3790 - val_loss: 4.8109 - val_accuracy: 0.0875\n",
            "Epoch 14/20\n",
            "338/338 [==============================] - 21s 59ms/step - loss: 1.9396 - accuracy: 0.4812 - val_loss: 4.6149 - val_accuracy: 0.0883\n",
            "Epoch 15/20\n",
            "338/338 [==============================] - 22s 63ms/step - loss: 1.9300 - accuracy: 0.4964 - val_loss: 4.8663 - val_accuracy: 0.0933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training accuracy has improved by a large margin which is a positive sign. However, the validation accuracy seems to not have had the same increase which could suggest overfitting or the model is not dealing with new data very well."
      ],
      "metadata": {
        "id": "TzL7hYcWtEVf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizer changed to Nadam to see if there are improvements over the base Adam optimizer."
      ],
      "metadata": {
        "id": "Hv_llMvDrEr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_model2.compile(optimizer='Nadam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VoCQOHI2rYVb"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = custom_model2.fit(\n",
        "    train_data,\n",
        "    steps_per_epoch=train_steps_per_epoch,\n",
        "    epochs=20,\n",
        "    validation_data=val_data,\n",
        "    validation_steps=val_steps_per_epoch,\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhKt8yLerblv",
        "outputId": "90d6ea7a-7ec3-43bf-dae9-f8bdef8ab4ec"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "338/338 [==============================] - 52s 83ms/step - loss: 2.8384 - accuracy: 0.2914 - val_loss: 4.1788 - val_accuracy: 0.1050\n",
            "Epoch 2/20\n",
            "338/338 [==============================] - 22s 60ms/step - loss: 2.5061 - accuracy: 0.3556 - val_loss: 4.5161 - val_accuracy: 0.0967\n",
            "Epoch 3/20\n",
            "338/338 [==============================] - 22s 60ms/step - loss: 2.3266 - accuracy: 0.4040 - val_loss: 4.3697 - val_accuracy: 0.1033\n",
            "Epoch 4/20\n",
            "338/338 [==============================] - 21s 60ms/step - loss: 2.0312 - accuracy: 0.4645 - val_loss: 4.8361 - val_accuracy: 0.0983\n",
            "Epoch 5/20\n",
            "338/338 [==============================] - 23s 66ms/step - loss: 1.7121 - accuracy: 0.5379 - val_loss: 4.7430 - val_accuracy: 0.0667\n",
            "Epoch 6/20\n",
            "338/338 [==============================] - 28s 79ms/step - loss: 1.5607 - accuracy: 0.5750 - val_loss: 4.6547 - val_accuracy: 0.1100\n",
            "Epoch 7/20\n",
            "338/338 [==============================] - 23s 64ms/step - loss: 1.2845 - accuracy: 0.6410 - val_loss: 4.7944 - val_accuracy: 0.0950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy of this model is better than the last indicating it is better fitting with the training data. Unfortunatelly, the val_accuracy is still not improving which continues to suggest possible overfitting."
      ],
      "metadata": {
        "id": "vnTzyINduQN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Optimizer Nadam was used as it yielded a higher accuracy with the categorical_crossentropy loss function.\n",
        "\n",
        "Loss function was changed to binary_crossentropy out of curiosity to see if any improvements can be made. I know this can not be used for our final model which is why it was commented out, but I wondered how putting the multi-class classification problem through a binary classification method would affect it."
      ],
      "metadata": {
        "id": "bqzyrQRyrku0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#custom_model3.compile(optimizer='Nadam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "cKC-D_Fkul9Z"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#history = custom_model3.fit(\n",
        "#    train_data,\n",
        "#    steps_per_epoch=train_steps_per_epoch,\n",
        "#    epochs=20,\n",
        "#    validation_data=val_data,\n",
        "#    validation_steps=val_steps_per_epoch,\n",
        "#    callbacks=[early_stopping, model_checkpoint]\n",
        "#)"
      ],
      "metadata": {
        "id": "y6fYjhWUun54"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model achieves the highest accuracy by a large margin but does still struggle with the problem of overfitting. It is interesting to see how this greatly improves the accuracy."
      ],
      "metadata": {
        "id": "OatUTybf3Hnj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Evaluation"
      ],
      "metadata": {
        "id": "GDaqlybkGp1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the best model"
      ],
      "metadata": {
        "id": "zAYQPNvp7B6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = load_model('best_model.h5')"
      ],
      "metadata": {
        "id": "WyEoHduF7EkC"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is used in order to get the predictions for the data along with the true labels."
      ],
      "metadata": {
        "id": "Dq68HbDe7JlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, data):\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    for batch in data:\n",
        "        images, labels = batch\n",
        "        predictions_batch = model.predict(images)\n",
        "        predictions.extend(np.argmax(predictions_batch, axis=1))\n",
        "        true_labels.extend(np.argmax(labels, axis=1))\n",
        "\n",
        "    return np.array(predictions), np.array(true_labels)"
      ],
      "metadata": {
        "id": "07_w5Rxz7H1Z"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve the predictions for both the custom models"
      ],
      "metadata": {
        "id": "GJMTDkCp7dpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_one, true_labels_one = get_predictions(custom_model1, val_data)\n",
        "predictions_two, true_labels_two = get_predictions(custom_model2, val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKmFoZwY7dWN",
        "outputId": "e6b35237-e0b3-4139-e928-f9bf35f61117"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 134ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the confusion matrices"
      ],
      "metadata": {
        "id": "Qvcm33_S7l7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix_one = confusion_matrix(true_labels_one, predictions_one)\n",
        "conf_matrix_two = confusion_matrix(true_labels_two, predictions_two)"
      ],
      "metadata": {
        "id": "Sm3RrjBx7oR6"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the confusion matrices"
      ],
      "metadata": {
        "id": "1rA98FcD7xn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "axes[0].matshow(conf_matrix_one, cmap='Blues')\n",
        "axes[0].set_title('Custom Model 1')\n",
        "axes[1].matshow(conf_matrix_two, cmap='Blues')\n",
        "axes[1].set_title('Custom Model 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "mrr4DSpZ7zt1",
        "outputId": "f5cd7b14-8f8f-44a5-c759-003915770f03"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_one = accuracy_score(true_labels_one, predictions_one)\n",
        "accuracy_two = accuracy_score(true_labels_two, predictions_two)\n",
        "\n",
        "print(f'Accuracy for Custom Model 1: {accuracy_one:.4f}')\n",
        "print(f'Accuracy for Custom Model 2: {accuracy_two:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwtD1cgk6xWY",
        "outputId": "c5bb2d23-d599-4750-9017-b28d447f462d"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Custom Model 1: 0.1050\n",
            "Accuracy for Custom Model 2: 0.1050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Write-up"
      ],
      "metadata": {
        "id": "SQ08sSYWGsUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenges\n",
        "\n",
        "1) One of the main problems faced while creating the models was achieving a good accuracy. The only way for me to achieve a good accuracy was to use binary crossentropy which is not applicable in this scenario as it is not a binary classification problem. To achieve the best accuracy I did using a multi-class problem required testing different layers and changing the optimizer and loss function to fit the model better and still did not yield a very good accuracy\n",
        "\n",
        "2) Overfitting was another issue faced. No matter what parameters were inputted, there was no increase in the val_Accuracy which could indecate the model was overfit. Even when the loss function was changed to the binary classification, the model still struggled with overfitting.\n",
        "\n",
        "3) Computational power was the final issue. These models took a long time to run and as the models improved they took more and more time to run. These can be effective in this scenario but may not work very well in a business setting."
      ],
      "metadata": {
        "id": "WjU6AsRM3YrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What worked and what did not\n",
        "\n",
        "1) the optimizer was best when set to Nadam. Initally, I tried the adam optimizer as it was a good general optimizer. However, the results achievied were not ideal so I tried using other optimizers and came across Nadam. This is an extension of Adam and was able to achieve a higher accuracy.\n",
        "\n",
        "2) The loss function yielded the highest accuracy when it was set to binary_crossentropy but this cant be used given the dataset. For this reason the loss function that must be used should be categorical_crossentropy. Unfortunately the accuracy achieved with this loss function is poor and also struggles with overfitting.\n",
        "\n",
        "3) Setting the early stop helped with the computational problem greatly. In some cases only 6 epochs would run which greatly reduced the time required to run the models. Without this the time required would be much higher with no meaningful improvements to the models."
      ],
      "metadata": {
        "id": "u4Uhh6cn4HqK"
      }
    }
  ]
}